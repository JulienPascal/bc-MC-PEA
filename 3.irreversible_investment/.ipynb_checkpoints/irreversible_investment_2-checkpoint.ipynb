{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84bc837f",
   "metadata": {
    "id": "84bc837f"
   },
   "source": [
    "# Solving the stochastic growth model with irreversible investment, using the bc-MC-PEA\n",
    "\n",
    "This notebook solves an optimal growth model with irreversible investment.\n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## I. Model: Optimal Growth Model with Irreversible Investment\n",
    "\n",
    "The planner’s problem is to choose consumption $\\{c_t\\}$ and next period’s capital $\\{k_{t+1}\\}$ to maximize expected utility,\n",
    "\n",
    "\\begin{equation}\n",
    "\\max_{\\{c_t,k_{t+1}\\}_{t=0}^\\infty} \\; E_0 \\sum_{t=0}^\\infty \\beta^t \\frac{c_t^{1-\\sigma}-1}{1-\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "subject to the resource constraint:\n",
    "\\begin{equation}\n",
    "k_{t+1} = z_t k_t^\\alpha - c_t + (1-\\delta)k_t,\n",
    "\\end{equation}\n",
    "constraint on investment:\n",
    "\\begin{equation}\n",
    "k_{t+1} \\geq (1-\\delta)k_t,\n",
    "\\end{equation}\n",
    "the law of motion for TFP:\n",
    "\\begin{equation}\n",
    "\\log(z_{t+1}) = \\rho \\log(z_t) + \\varepsilon_{t+1},\n",
    "\\end{equation}\n",
    "\n",
    "The associated FOCs are:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "c_t^{-\\sigma} - \\mu_t &= \\beta E_t \\left\\{ c_{t+1}^{-\\sigma} \\left[\\alpha z_{t+1} k_{t+1}^{\\alpha-1} + 1-\\delta \\right] - \\mu_{t+1} (1 - \\ \\delta)\\right\\}, \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu_t ( k_{t+1} - (1-\\delta)k_t) = 0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu_t \\geq 0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "#### Expectation Function $E_t[\\phi_{t+1}]$:\n",
    "$$\n",
    "\\phi_{t+1} \\equiv \\beta  \\Big( c_{t+1}^{-\\sigma} \\left[\\alpha z_{t+1} k_{t+1}^{\\alpha-1} + 1-\\delta \\right] - \\mu_{t+1} (1 - \\ \\delta).\n",
    "\\Big)$$\n",
    "As in the standard case, a parametric approximation is used. For example, one may posit the following log-log model:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\log(E_t[\\phi_{t+1}]) & = \\theta_0 + \\theta_1 \\log k_t + \\theta_2 \\log z_t + \\theta_3 \\left(\\log k_t\\right)^2 + \\theta_4 \\left(\\log z_t\\right)^2 + \\theta_5 \\log k_t \\cdot \\log z_t \\\\\n",
    "& = \\boldsymbol{s}_t' \\boldsymbol{\\theta}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Implied consumption\n",
    "\n",
    "Under the assumption that the constraint does not bind:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{c}_t = \\exp(\\boldsymbol{s}_t' \\boldsymbol{\\theta})^{-1/\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "Consumption choice $\\tilde{c}_t$ implies a savings choice: $\\tilde{k}_{t+1} = z_t k_t^\\alpha - \\tilde{c}_t + (1-\\delta)k_t$. Two cases can occur:\n",
    "\n",
    "1. If $\\tilde{k}_{t+1} \\geq (1-\\delta)k_t$, then the irreversible investment constraint does not bind:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "c_t & = \\tilde{c}_t \\\\\n",
    "k_{t+1} &= \\tilde{k}_{t+1} \\\\\n",
    "\\mu_t & = 0\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "2. If $\\tilde{k}_{t+1} < (1-\\delta)k_t$, then the irreversible investment constraint binds and we recover $c_t$ from the budget constraint:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "c_t & = z_t k_t^\\alpha \\\\\n",
    "k_{t+1} & = (1-\\delta)k_t \\\\\n",
    "\\mu_t & > 0\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "In case 2, the value of the lagrange multiplier is then: \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mu_t & = c_t^{-\\sigma} - \\beta E_t \\left\\{ c_{t+1}^{-\\sigma} \\left[\\alpha z_{t+1} k_{t+1}^{\\alpha-1} + 1-\\delta \\right] - \\mu_{t+1} (1 - \\ \\delta)\\right\\} \\\\\n",
    "& \\approx c_t^{-\\sigma} - \\exp(\\boldsymbol{s}_t' \\boldsymbol{\\theta})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "provided that $\\exp(\\boldsymbol{s}_t' \\boldsymbol{\\theta})$ approximates correctly the conditional expectation.\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "#### Euler equation error\n",
    "\n",
    "unit-less Euler equation error (EEE):\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    EEE & = 1 - \\frac{1}{c_t} \\Big( \\beta E_t \\left\\{ c_{t+1}^{-\\sigma} \\left[\\alpha z_{t+1} k_{t+1}^{\\alpha-1} + 1-\\delta \\right]  -\\mu_{t+1} (1 - \\ \\delta) \\right\\} + \\mu_t \\Big)^{-1/\\sigma}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Mean square integration error of the OLS forecast\n",
    "\n",
    "mean square integration error (MSIE) is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "    E\\Big[\\big(\\boldsymbol{s}_m' \\boldsymbol{\\theta^{*}} - \\boldsymbol{s}_m' \\boldsymbol{\\theta^{(n)}}\\big)^{2} \\Big] = \\frac{\\sigma_{g,\\varepsilon}^2 k}{N(M-k-1)}, \\quad \\text{for } M > k+1\n",
    "\\end{equation}\n",
    "\n",
    "where, by assumption, the true value for the conditional expectation is given by $E_t[\\phi_{t+1}] = \\boldsymbol{s}_m' \\boldsymbol{\\theta^{*}}$.\n",
    "\n",
    "In practice, $\\boldsymbol{\\theta^{*}}$ is unknow, and instead I calculate $E_t[\\phi_{t+1}]$ very accurately, using a Gaussian quadrature for the integral with respect to the innovation variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16a7fd",
   "metadata": {
    "id": "4b16a7fd"
   },
   "source": [
    "---\n",
    "\n",
    "## II. Computations\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "### II. A. Load libraries, functions and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57125189-4eb6-4bf7-9d0f-20a551053ea5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57125189-4eb6-4bf7-9d0f-20a551053ea5",
    "outputId": "c7d8462d-6e9c-4faa-dcfb-c2c822a7dd89"
   },
   "outputs": [],
   "source": [
    "on_Colab = False #True\n",
    "import time, os\n",
    "\n",
    "def is_chaospy_installed():\n",
    "    try:\n",
    "        import chaospy\n",
    "        return True\n",
    "    except ModuleNotFoundError:\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "if is_chaospy_installed():\n",
    "    print(\"chaospy is installed.\")\n",
    "else:\n",
    "    print(\"chaospy is not installed.\")\n",
    "\n",
    "# Install deps on Colab\n",
    "if (on_Colab == True) & (is_chaospy_installed() == False):\n",
    "    print(\"Installing packages...\")\n",
    "    %shell pip install -v quantecon interpolation chaospy --user\n",
    "    #Restart runtime\n",
    "    print(\"Runtime is now restarting...\")\n",
    "    print(\"You can ignore the error message [Your session crashed for an unknown reason.]\")\n",
    "    time.sleep(0.5)\n",
    "    os._exit(0)  # restart\n",
    "    # torch torchcontrib torch-optimizer\n",
    "else:\n",
    "    print(\"Packages already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cba24",
   "metadata": {
    "id": "f00cba24"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import scipy.stats\n",
    "import chaospy  ## for quadrature\n",
    "from itertools import product\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "from tqdm import tqdm as tqdm\n",
    "import datetime\n",
    "from typing import Tuple\n",
    "class Vector: pass\n",
    "from scipy.stats import norm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, TensorDataset\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# To create copies of NN\n",
    "import copy\n",
    "import matplotlib.ticker as mtick\n",
    "# To use sparse kronecker product\n",
    "from scipy import sparse\n",
    "\n",
    "import itertools\n",
    "# Interpolations\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "# Regressions\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "lowess = sm.nonparametric.lowess\n",
    "\n",
    "import quantecon as qe\n",
    "from interpolation import interp\n",
    "from quantecon.optimize import brentq\n",
    "from numba import njit\n",
    "#from numba.experimental import jitclass\n",
    "#import copy # Not used so far\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import platform,socket,re,uuid,json,psutil,logging, cpuinfo, shutil\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141aaee",
   "metadata": {
    "id": "6141aaee"
   },
   "outputs": [],
   "source": [
    "# Store parameters\n",
    "class MyParams():\n",
    "    \"\"\"\n",
    "    N: number of draws for innovation vector\n",
    "    M: number of draws for the state vector\n",
    "    ...\n",
    "    \"\"\"\n",
    "    def __init__(self, N, M, lr, optimizer, nb_epochs, order_gauss,\n",
    "                 beta, alpha, gamma, delta, std_tfp, rho_tfp,\n",
    "                 regression_two_steps, feasible_GLS, effective_sample_size):\n",
    "        # Model parameters\n",
    "        self.beta = beta # Discount factor (patience)\n",
    "        self.alpha = alpha # Capital share in production\n",
    "        self.gamma = gamma # CRRA coefficient\n",
    "        self.one_min_gamma = 1 - gamma #pre-compute\n",
    "        # depreciation rate capital\n",
    "        self.delta = delta\n",
    "        # Standard deviation exo random variables\n",
    "        self.std_tfp = std_tfp #0.01\n",
    "        # Mean value exo random variables\n",
    "        self.mean_tfp = 1.0\n",
    "        # Persistence params\n",
    "        self.rho_tfp = rho_tfp # Persistence log TFP values\n",
    "        # Non stochastic steady state calculations\n",
    "        self.kss = ((1 - self.beta * (1 - self.delta)) / (self.alpha * self.beta)) ** (1 / (self.alpha - 1))\n",
    "        self.std_k = 0 #std. dev capital\n",
    "        self.css = self.kss**self.alpha - self.delta*self.kss\n",
    "        self.std_c = 0 #std. dev consumption\n",
    "        self.zss = 1\n",
    "        self.std_z = 0\n",
    "        self.tol_c = 1e-3 #to prevent negative consumption\n",
    "        # Dependent variable in level or log\n",
    "        self.formula = \"\"\n",
    "        # Options for OLS regression\n",
    "        self.center_dep_var = False #True #False #demean\n",
    "        self.normalize_dep_var = False #True #False #divide by std. dev\n",
    "        self.nb_expl_vars = 10   # including constant\n",
    "        if self.nb_expl_vars not in (4, 6, 10):\n",
    "            raise ValueError( f\"nb_expl_vars must be one of (4, 6, 10); got {self.nb_expl_vars}\"  )\n",
    "        self.basis = 2          # 1: monomial, 2: Chebyshev\n",
    "        if self.basis not in (1, 2):\n",
    "            raise ValueError( f\"basis must be either 1 (monomial) or 2 (Chebyshev); got {self.basis}\" )\n",
    "        self.regression_two_steps = regression_two_steps #Use the two-step regression described in appendix (approximation to full GLS)\n",
    "        self.feasible_GLS = feasible_GLS #\n",
    "        if self.regression_two_steps and self.feasible_GLS:\n",
    "            raise RuntimeError(\"Both regression_two_steps and feasible_GLS are True. Choose one of the options.\")\n",
    "        # Correction for serial correlation in dependent variables\n",
    "        self.effective_sample_size = effective_sample_size\n",
    "        self.nb_shocks = 1\n",
    "        ## State: Distribution of wealth + TFP (no persistence depreciation shocks)\n",
    "        self.dim_state = 2\n",
    "        ## Input for neural net\n",
    "        self.dim_input = 2\n",
    "        self.dim_output = 1\n",
    "        # Nb agents:\n",
    "        self.nb_agents = 1 #One representative household\n",
    "        # Functions\n",
    "        ## Utility\n",
    "        if self.gamma != 1:\n",
    "            self.u = lambda c: (1/self.one_min_gamma)*(c**(self.one_min_gamma) - 1)\n",
    "        else:\n",
    "            self.u = lambda c: torch.log(c)\n",
    "        self.u_prime =  lambda c: c**(-self.gamma)\n",
    "        self.u_prime_inv =  lambda c: c**(-(1/self.gamma))\n",
    "        # bc-MC hyperparameters\n",
    "        self.N = N #number of iid shocks used for each value of the state vector\n",
    "        self.M = M #number of iid realization of the state vector\n",
    "        self.MN = int(M*N)\n",
    "        # To keep constant the number of function evaluations\n",
    "        self.T = int((M*N)/2) #number\n",
    "        self.distribution_shocks = \"Normal\" #\"Normal\" #Lognormal\n",
    "        # Learning parameters\n",
    "        self.lr = lr\n",
    "        self.momentum = 0.9 #momentum for SGD with momentum\n",
    "        self.optimizer = optimizer #\"Adam\" #default: #Adam or SGD or SWA\n",
    "        self.freq_gamma = 0.95 #When using a scheduler for the learning rate, lr_{t} = freq_gamma*lr_{t-1}\n",
    "        self.use_scheduler = False #If true, use a scheduler for the learning rate\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.freq_scheduler = 1000\n",
    "        # GAUSSIAN QUADRATURE\n",
    "        ## INNOVATION VECTOR\n",
    "        strr = \"chaospy.Normal(0, self.std_tfp)\"\n",
    "        self.distrib = eval('chaospy.J({})'.format(strr))\n",
    "        self.order_gauss = order_gauss\n",
    "        nodes, weights = chaospy.generate_quadrature(self.order_gauss, self.distrib, rule = \"gaussian\", sparse=True) #dist(self.order_gauss, self.distrib, rule = \"gaussian\", sp=True)\n",
    "        self.nodes = nodes\n",
    "        self.nodes_flat =  self.nodes.flatten() #make 1d array\n",
    "        self.weights = weights\n",
    "        self.weights_torch = torch.tensor(weights)\n",
    "        self.nodes_torch = torch.tensor(np.transpose(self.nodes)) #column=dim. Row=observation\n",
    "        # Save the number of points for the guassian quadrature:\n",
    "        self.N_gaussian = len(self.weights_torch)\n",
    "        # Implied number of points for the current space (T=MN/2 <-> M = 2T/N)\n",
    "        self.M_gaussian = int((2*self.T)/self.N_gaussian)\n",
    "        self.MN_gaussian = self.N_gaussian*self.M_gaussian\n",
    "        # Repeat nodes to match the number of function evaluations for the expectation\n",
    "        self.nodes_torch_repeated = self.nodes_torch.repeat(self.M_gaussian, 1)\n",
    "\n",
    "\n",
    "def show_params(params, limited=True):\n",
    "    \"\"\"\n",
    "    Function to display parameter values\n",
    "    \"\"\"\n",
    "    print(\"learning rate: {}\".format(params.lr))\n",
    "    print(\"nb epochs: {}\".format(params.nb_epochs))\n",
    "    print(\"M: {}\".format(params.M))\n",
    "    print(\"N: {}\".format(params.N))\n",
    "    print(\"MN: {}\".format(params.MN))\n",
    "    print(\"T: {}\".format(params.T))\n",
    "    print(\"optimizer_chosen: {}\".format(params.optimizer))\n",
    "    print(\"use_scheduler: {}\".format(params.use_scheduler))\n",
    "    print(\"center_dep_var: {}\".format(params.center_dep_var))\n",
    "    print(\"normalize_dep_var: {}\".format(params.normalize_dep_var))\n",
    "    print(\"nb_expl_vars: {}\".format(params.nb_expl_vars))\n",
    "    print(\"basis: {}\".format(params.basis))\n",
    "    print(\"regression_two_steps: {}\".format(params.regression_two_steps))\n",
    "    print(\"feasible_GLS: {}\".format(params.feasible_GLS))\n",
    "    print(\"effective_sample_size: {}\".format(params.effective_sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbac91-b912-4c0f-8a9a-883be65112a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2bbac91-b912-4c0f-8a9a-883be65112a2",
    "outputId": "21fb9e77-7c82-47f1-8162-9681bfb90c08"
   },
   "outputs": [],
   "source": [
    "info_cpu = cpuinfo.get_cpu_info()\n",
    "for (name) in info_cpu:\n",
    "  print(f\"{name}: \", info_cpu[name])\n",
    "\n",
    "same_machine = True #ensure same machine\n",
    "machine_desired = \"Intel(R) Xeon(R) CPU @ 2.20GHz\"\n",
    "machine_desired = \"AMD EPYC 7B12\"\n",
    "\n",
    "\n",
    "if (on_Colab == True):\n",
    "    if info_cpu['brand_raw'] != machine_desired:\n",
    "      print(f\"Machine is: {info_cpu['brand_raw']}. RESTARTING VM\")\n",
    "      print(\"You can ignore the error message [Your session crashed for an unknown reason.]\")\n",
    "      time.sleep(0.5)\n",
    "      os._exit(0)  # restart\n",
    "    else:\n",
    "      print(f\"Found desired machine: {machine_desired}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe5dbb-ebdc-4262-a9ff-1479f87edd18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "b9fe5dbb-ebdc-4262-a9ff-1479f87edd18",
    "outputId": "ffbf1e31-e10c-4be8-a33a-454b717d0bb2"
   },
   "outputs": [],
   "source": [
    "current_wd = os.getcwd()\n",
    "print(current_wd)\n",
    "output_extension = \"irreversible_investment_2\"\n",
    "output_folder = output_extension + \"/\"\n",
    "print(output_folder)\n",
    "\n",
    "# Create folder if does not exist:\n",
    "if not os.path.exists(output_folder):\n",
    "    # If it doesn't exist, create it\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Create folder to save models\n",
    "output_folder_models = output_folder + '/models/'\n",
    "if not os.path.exists(output_folder_models):\n",
    "    # If it doesn't exist, create it\n",
    "    os.makedirs(output_folder_models)\n",
    "\n",
    "if on_Colab == True:\n",
    "    # Mount gdrive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    # For final save\n",
    "    g_drive_path = '/gdrive/My Drive/bc_MC_PEA/6.irreversible_investment/'\n",
    "    # Small test\n",
    "    with open(g_drive_path + 'fooHello.txt', 'w') as f:\n",
    "        f.write('Hello Google Drive!')\n",
    "\n",
    "    # Autosave every 60 seconds\n",
    "    %autosave 60\n",
    "\n",
    "\n",
    "# If on Colab, install Octave and Matlab\n",
    "if on_Colab == True:\n",
    "    # Step 1: Install Octave\n",
    "    !apt-get install -y octave\n",
    "    !octave --version\n",
    "\n",
    "    # Step 2: Install Dynare (this might take a bit of time)\n",
    "    !apt-get install -y dynare\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6510f",
   "metadata": {
    "id": "63d6510f"
   },
   "outputs": [],
   "source": [
    "# Load functions\n",
    "plot_scale = 0.75\n",
    "plt.rcParams[\"figure.figsize\"] = (plot_scale*16, plot_scale*9)\n",
    "# Controlling fontsizes\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = SMALL_SIZE + 2\n",
    "BIGGER_SIZE =  SMALL_SIZE + 4\n",
    "plt.rcParams['legend.fontsize'] = MEDIUM_SIZE\n",
    "dpi_chosen=600 #control the quality of .png\n",
    "linewidth_chosen = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f65cbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7f65cbf",
    "outputId": "ab16d96b-ae76-479c-a091-45311f44d725",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M_chosen = 200 #200 #200 #100 #Nb draws state vector\n",
    "N_chosen = 2 #Nb draws innovation vector for each realization of the state vector\n",
    "lr_chosen = 1e-5 #1e-4 #4 #1e-4 #3 #5 #1e-3 #default: 1e-4 #3 #Learning rate\n",
    "nb_epochs_chosen = 2000 #2000\n",
    "order_gauss_chosen = 5 #number of Gaussian nodes for integration wrt to innovation vector\n",
    "optimizer_chosen = \"Adam\" #\"Adam\" #\"NAdam\" # default: \"Adam\"\n",
    "\n",
    "# Parametrization RBC\n",
    "beta_chosen = 0.96 #0.95 #discount factor\n",
    "alpha_chosen = 0.36 #production params\n",
    "std_tfp_chosen = 0.014 #25 #025 #125 #0.125 #0.01 #0.125 #std tfp. High value for constraint to bind\n",
    "gamma_chosen = 1.0 #CRRA parameter\n",
    "rho_chosen = 0.92 #persistence TFP\n",
    "delta_chosen = 0.1 #0.1 #depreciation rate\n",
    "\n",
    "# Parametrization Irreversible\n",
    "beta_chosen = 0.95 #0.95 #discount factor\n",
    "alpha_chosen = 0.3 #production params\n",
    "std_tfp_chosen = 0.14 #25 #025 #125 #0.125 #0.01 #0.125 #std tfp. High value for constraint to bind\n",
    "gamma_chosen = 1.0 #CRRA parameter\n",
    "rho_chosen = 0.8 #persistence TFP\n",
    "delta_chosen = 0.1 #0.1 #0.1 #depreciation rate\n",
    "\n",
    "mu_chosen = 1e-5 #e-6 #1e-5 #1e-6 #1e-6 #parameter gradient free bc-MC\n",
    "mu_threshold = 1e-10 #min value for mu\n",
    "mu_decay_chosen = 1.0 #0.999\n",
    "use_Lookahead_chosen = False #Lookahead optimizer\n",
    "\n",
    "# Options\n",
    "regression_two_steps_chosen = False\n",
    "feasible_GLS_chosen = False\n",
    "effective_sample_size_chosen = True\n",
    "\n",
    "params = MyParams(N_chosen, M_chosen, lr_chosen, optimizer_chosen,\n",
    "                  nb_epochs_chosen, order_gauss_chosen,\n",
    "                  beta_chosen, alpha_chosen, gamma_chosen, delta_chosen,\n",
    "                  std_tfp_chosen, rho_chosen,\n",
    "                  regression_two_steps_chosen, \n",
    "                  feasible_GLS_chosen, effective_sample_size_chosen)\n",
    "\n",
    "show_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88e796-a6e5-4072-b9e6-6d443a5e25c4",
   "metadata": {
    "id": "0b88e796-a6e5-4072-b9e6-6d443a5e25c4"
   },
   "source": [
    "### II.B. Model WITHOUT constraint\n",
    "\n",
    "Solve model without constraint, to have a starting point. The FOC is:\n",
    "\n",
    "The associated FOCs are:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "c_t^{-\\sigma} & = \\beta E_t \\left\\{ c_{t+1}^{-\\sigma} \\left[\\alpha z_{t+1} k_{t+1}^{\\alpha-1} + 1-\\delta \\right] \\right\\}, \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### II.B.1. 1st order solution using Dynare. Ignore constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56badf1c-7d4e-453f-bbc9-570d217cb6f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56badf1c-7d4e-453f-bbc9-570d217cb6f1",
    "outputId": "d73e172b-2e2f-4ba0-ce52-258abf78d770",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = \"neogrowth.mod\"\n",
    "dirpath = os.getcwd()  # Get the current working directory\n",
    "fpath = os.path.join(dirpath, fname)\n",
    "\n",
    "if on_Colab == True:\n",
    "  dirpath = output_folder  # Get the current working directory\n",
    "  fpath = os.path.join(dirpath, fname)\n",
    "  with open(output_folder + 'fooColab.txt', 'w') as f:\n",
    "    f.write('Hello Google Drive!')\n",
    "\n",
    "file_content_1 = \"\"\"\n",
    "% optimal_growth.mod\n",
    "% Dynare file for the standard optimal growth model (first-order approximation)\n",
    "\n",
    "var k c z;\n",
    "varexo eps;\n",
    "\n",
    "parameters beta gamma alpha delta rho sigma_eps;\n",
    "\n",
    "% Parameter values\n",
    "beta      = {beta};\n",
    "gamma     = {gamma};      % CRRA coefficient\n",
    "alpha     = {alpha};\n",
    "delta     = {delta};\n",
    "rho       = {rho_tfp};\n",
    "sigma_eps = {std_tfp};\n",
    "\n",
    "model;\n",
    "% Euler equation (after substituting the marginal utility condition)\n",
    "c^(-gamma) = beta * c(+1)^(-gamma) * ( alpha * z(+1) * k^(alpha-1) + 1 - delta );\n",
    "\n",
    "% Resource constraint (law of motion for capital)\n",
    "k = z * k(-1)^alpha - c + (1-delta)*k(-1);\n",
    "\n",
    "% Technology process (AR(1) in logs)\n",
    "log(z) = rho*log(z(-1)) + eps;\n",
    "\n",
    "end;\n",
    "\n",
    "initval;\n",
    "% Initial guesses for the steady state\n",
    "k   = ((alpha*beta)/(1 - beta*(1-delta)))^(1/(1-alpha));\n",
    "c   = ((alpha*beta)/(1 - beta*(1-delta)))^(alpha/(1-alpha)) - delta*(((alpha*beta)/(1 - beta*(1-delta)))^(alpha/(1-alpha)));\n",
    "z   = 1;\n",
    "eps = 0;\n",
    "end;\n",
    "\n",
    "steady;\n",
    "check;\n",
    "\n",
    "shocks;\n",
    "var eps = sigma_eps^2;\n",
    "end;\n",
    "\n",
    "% IRF\n",
    "stoch_simul(order=1, irf=100);\n",
    "\n",
    "% SIMULATED SERIES\n",
    "stoch_simul(periods=50000);\n",
    "\"\"\".format(beta = params.beta, alpha = params.alpha,  gamma = params.gamma,\n",
    "           delta = params.delta, std_tfp = params.std_tfp, rho_tfp = params.rho_tfp)\n",
    "\n",
    "file_content = file_content_1\n",
    "# Concat stings\n",
    "# Write the content to the file\n",
    "with open(fpath, \"w\") as file:\n",
    "    file.write(file_content)\n",
    "\n",
    "root_path = \"\"\n",
    "if on_Colab == False:\n",
    "    # Run the shell script locally.\n",
    "    print(\"Calculating linearized model using Dynare\")\n",
    "    result = subprocess.run(['./solve_neogrowth.sh'], capture_output=True, text=True)\n",
    "    # Print the output of the script\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "# Desgined to run on Google Colab\n",
    "else:\n",
    "    print(\"Calculating linearized model using Octave Dynare\")\n",
    "    root_path = output_folder\n",
    "\n",
    "    # Now modify the .m file to include cd at top (before running)\n",
    "    with open(g_drive_path + 'solve_neogrowth_octave.m', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Insert cd command at top (right after patches if any)\n",
    "    lines.insert(0, f\"cd '{output_folder}';\\n\")\n",
    "\n",
    "    with open('solve_neogrowth_octave_2.m', 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    # Now run it\n",
    "    !octave solve_neogrowth_octave_2.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf3e93-950a-4316-ae7d-69eb734c43e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4ddf3e93-950a-4316-ae7d-69eb734c43e7",
    "outputId": "fb4b4630-3f48-40ef-d904-937275166040",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load simulated data and fit linear model\n",
    "SS_values = pd.read_csv(root_path + \"output/Linearization/SS_values.csv\")\n",
    "print(SS_values)\n",
    "\n",
    "Sim_series = pd.read_csv(root_path + \"output/Linearization/Sim_series.csv\")\n",
    "print(Sim_series)\n",
    "\n",
    "# Load the data\n",
    "Sim_series = pd.read_csv(root_path + \"output/Linearization/Sim_series.csv\")\n",
    "\n",
    "## Simulate realization conditional expectation\n",
    "Sim_series['c_plus_1'] = Sim_series['c'].shift(-1)\n",
    "Sim_series['z_plus_1'] = Sim_series['z'].shift(-1)\n",
    "Sim_series['k_plus_1'] = Sim_series['k'].shift(-1)\n",
    "Sim_series['cond_exp'] = params.beta  * (Sim_series['c_plus_1']**(-params.gamma)) * ( params.alpha * Sim_series['z_plus_1'] * Sim_series['k_plus_1']**(params.alpha - 1) + 1 - params.delta )\n",
    "# Production\n",
    "Sim_series['cash'] = Sim_series['z'] * Sim_series['k']**params.alpha + (1 - params.delta)*Sim_series['k'] - Sim_series['c']\n",
    "# Log tfp\n",
    "Sim_series['a'] = np.log(Sim_series['z'])\n",
    "params.std_z = np.std(Sim_series['z'])\n",
    "\n",
    "# Centered vars\n",
    "Sim_series['c_demeaned'] = Sim_series['c'] - params.css\n",
    "Sim_series['a_demeaned'] = Sim_series['a'] # mean is 0\n",
    "Sim_series['z_demeaned'] = Sim_series['z'] - params.zss\n",
    "Sim_series['k_demeaned'] = Sim_series['k'] - params.kss\n",
    "\n",
    "# Normalize vars:\n",
    "params.std_c = np.std(Sim_series['c'])\n",
    "params.std_a = np.std(Sim_series['a'])\n",
    "params.std_z = np.std(Sim_series['z'])\n",
    "params.std_k = np.std(Sim_series['k'])\n",
    "\n",
    "Sim_series['c_normalized'] = Sim_series['c_demeaned']/params.std_c\n",
    "Sim_series['a_normalized'] = Sim_series['a_demeaned']/params.std_a\n",
    "Sim_series['z_normalized'] = Sim_series['z_demeaned']/params.std_z\n",
    "Sim_series['k_normalized'] = Sim_series['k_demeaned']/params.std_k\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.suptitle('Log variables')\n",
    "ax1.hist(np.log(Sim_series['c']))\n",
    "ax1.set_title(\"Log c\")\n",
    "ax2.hist(Sim_series['a'])\n",
    "ax2.set_title(\"a (log z)\")\n",
    "ax3.hist(np.log(Sim_series['k']))\n",
    "ax3.set_title(\"Log k\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "fig.suptitle('Normalized variables')\n",
    "ax1.hist(Sim_series['c_normalized'])\n",
    "ax1.set_title(\"c normalized\")\n",
    "ax2.hist(Sim_series['a_normalized'])\n",
    "ax2.set_title(\"a normalized\")\n",
    "ax3.hist(Sim_series['k_normalized'])\n",
    "ax3.set_title(\"k normalized\")\n",
    "ax4.hist(Sim_series['z_normalized'])\n",
    "ax4.set_title(\"z normalized\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Transformed version of the conditional expectation\n",
    "## Euler: 1 = E_t(...)\n",
    "## c_t = E_t(c_t * (...))\n",
    "Sim_series['cond_exp_2'] = Sim_series['c'] * params.beta  * ( (Sim_series['c_plus_1']/Sim_series['c'])**(-params.gamma) ) * ( params.alpha * Sim_series['z_plus_1'] * Sim_series['k_plus_1']**(params.alpha - 1) + 1 - params.delta )\n",
    "\n",
    "## c_t/cash_t = E_t(c_t/cash_ * (...))\n",
    "Sim_series['cond_exp_3'] = (Sim_series['c']/Sim_series['cash']) * params.beta  * ((Sim_series['c_plus_1']/Sim_series['c'])**(-params.gamma)) * ( params.alpha * Sim_series['z_plus_1'] * Sim_series['k_plus_1']**(params.alpha - 1) + 1 - params.delta )\n",
    "\n",
    "## (c_t/c_ss)**(-sigma) = E_t()\n",
    "Sim_series['cond_exp_4'] = params.beta  * ((Sim_series['c_plus_1']/params.css)**(-params.gamma)) * ( params.alpha * Sim_series['z_plus_1'] * Sim_series['k_plus_1']**(params.alpha - 1) + 1 - params.delta )\n",
    "\n",
    "# kt+1\n",
    "Sim_series['cond_exp_5'] = params.beta * Sim_series['k_plus_1'] * ((Sim_series['c_plus_1']/Sim_series['c'])**(-params.gamma)) * ( params.alpha * Sim_series['z_plus_1'] * Sim_series['k_plus_1']**(params.alpha - 1) + 1 - params.delta )\n",
    "\n",
    "# Percentage diff from c_ss\n",
    "Sim_series['cond_exp_6'] = params.beta  * ((Sim_series['c_plus_1']/params.css)**(-params.gamma)) * ( params.alpha * Sim_series['z_plus_1'] * Sim_series['k_plus_1']**(params.alpha - 1) + 1 - params.delta ) - 1\n",
    "\n",
    "# rhs Euler, in logs\n",
    "Sim_series['cond_exp_7'] = np.log(Sim_series['cond_exp'])\n",
    "\n",
    "df_Dynare = pd.DataFrame({'k': Sim_series['k'], 'z': Sim_series['z'], 'a': Sim_series['a'],\n",
    "                          'k_demeaned': Sim_series['k_demeaned'], 'a_demeaned': Sim_series['a_demeaned'], 'z_demeaned': Sim_series['z_demeaned'],\n",
    "                          'k_normalized': Sim_series['k_normalized'], 'a_normalized': Sim_series['a_normalized'], 'z_normalized': Sim_series['z_normalized'],\n",
    "                          'cond_exp':  Sim_series['cond_exp'],\n",
    "                          'cond_exp_2':  Sim_series['cond_exp_2'],\n",
    "                         'cond_exp_3':  Sim_series['cond_exp_3'],\n",
    "                         'cond_exp_4':  Sim_series['cond_exp_4'],\n",
    "                         'cond_exp_5':  Sim_series['cond_exp_5'],\n",
    "                         'cond_exp_6':  Sim_series['cond_exp_6'],\n",
    "                         'cond_exp_7':  Sim_series['cond_exp_7']\n",
    "                         })\n",
    "\n",
    "print(df_Dynare.head())\n",
    "\n",
    "## Log-log model\n",
    "model = smf.ols(formula='np.log(cond_exp) ~ np.log(k) + np.log(z) + I(np.log(k)**2) + I(np.log(z)**2) + np.log(k)*np.log(z)', data=df_Dynare).fit()\n",
    "print(model.summary())\n",
    "\n",
    "cond_exp_chosen = 7\n",
    "if (params.center_dep_var == True) & (params.normalize_dep_var == True):\n",
    "    x1_chosen = \"k_normalized\"\n",
    "    x2_chosen = \"a_normalized\"\n",
    "elif (params.center_dep_var == True) & (params.normalize_dep_var == False):\n",
    "    x1_chosen = \"k_demeaned\"\n",
    "    x2_chosen = \"a_demeaned\"\n",
    "else:\n",
    "    x1_chosen = \"np.log(k)\"\n",
    "    x2_chosen = \"a\"\n",
    "\n",
    "\n",
    "\n",
    "if params.nb_expl_vars == 4:\n",
    "    # only main + interaction\n",
    "    formula_OLS = (\n",
    "        f\"cond_exp_{cond_exp_chosen} ~ \"\n",
    "        f\"{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen}\"\n",
    "    )\n",
    "\n",
    "elif params.nb_expl_vars == 6:\n",
    "    if params.basis == 1:\n",
    "        # monomial up to degree 2\n",
    "        formula_OLS = (\n",
    "            f\"cond_exp_{cond_exp_chosen} ~ \"\n",
    "            f\"{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + \"\n",
    "            f\"I({x1_chosen}**2) + I({x2_chosen}**2)\"\n",
    "        )\n",
    "    else:\n",
    "        # Chebyshev up to order 2\n",
    "        formula_OLS = (\n",
    "            f\"cond_exp_{cond_exp_chosen} ~ \"\n",
    "            f\"{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + \"\n",
    "            f\"I({x1_chosen}**2 - 1) + I({x2_chosen}**2 - 1)\"\n",
    "        )\n",
    "\n",
    "elif params.nb_expl_vars == 10:\n",
    "    if params.basis == 1:\n",
    "        # monomial up to degree 3\n",
    "        formula_OLS = (\n",
    "            f\"cond_exp_{cond_exp_chosen} ~ \"\n",
    "            f\"{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + \"\n",
    "            f\"I({x1_chosen}**2) + I({x2_chosen}**2) + \"\n",
    "            f\"I({x1_chosen}**3) + I({x1_chosen}**2*{x2_chosen}) + \"\n",
    "            f\"I({x1_chosen}*{x2_chosen}**2) + I({x2_chosen}**3)\"\n",
    "        )\n",
    "    else:\n",
    "        # Chebyshev up to order 3\n",
    "        formula_OLS = (\n",
    "            f\"cond_exp_{cond_exp_chosen} ~ \"\n",
    "            f\"{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + \"\n",
    "            f\"I({x1_chosen}**2 - 1) + I({x2_chosen}**2 - 1) + \"\n",
    "            f\"I(4*{x1_chosen}**3 - 3*{x1_chosen}) + \"\n",
    "            f\"I(4*{x2_chosen}**3 - 3*{x2_chosen}) + \"\n",
    "            f\"I(({x1_chosen}**2 - 1)*{x2_chosen}) + \"\n",
    "            f\"I({x1_chosen}*({x2_chosen}**2 - 1))\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"nb_expl_vars must be one of 4,6,10; got {params.nb_expl_vars}\"\n",
    "    )\n",
    "\n",
    "model = smf.ols(formula=formula_OLS, data=df_Dynare).fit()\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "plt.hist(model.resid)\n",
    "plt.show()\n",
    "\n",
    "coeff_vector = model.params\n",
    "print(coeff_vector)\n",
    "\n",
    "coeff_array_0 = model.params.values\n",
    "print(coeff_array_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c87d13-c337-491e-b530-e5e806215f16",
   "metadata": {
    "id": "71c87d13-c337-491e-b530-e5e806215f16"
   },
   "source": [
    "#### II.B.2. Basline PEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fd9ec-76fb-448f-a51d-c1fcf2d76bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def fill_X_row(X, i, x1, x2, nb_expl_vars, basis):\n",
    "    \"\"\"\n",
    "    Fill row i of the design matrix X in place, using either\n",
    "      - basis=1 : monomial basis\n",
    "      - basis=2 : Chebyshev basis\n",
    "    up to nb_expl_vars terms (4, 6 or 10).\n",
    "    \n",
    "    After calling this, X[i,:] will be set.\n",
    "    \"\"\"\n",
    "    if nb_expl_vars == 4:\n",
    "        # simple cross basis\n",
    "        X[i, :] = np.array([1, x1, x2, x1*x2])\n",
    "        return\n",
    "\n",
    "    if basis == 1:\n",
    "        # —— Monomial basis ——\n",
    "        if nb_expl_vars == 6:\n",
    "            # total degree ≤2\n",
    "            X[i, :] = np.array([\n",
    "                1,\n",
    "                x1,\n",
    "                x2,\n",
    "                x1 * x2,\n",
    "                x1**2,\n",
    "                x2**2\n",
    "            ])\n",
    "        elif nb_expl_vars == 10:\n",
    "            # total degree ≤3\n",
    "            X[i, :] = np.array([\n",
    "                1,\n",
    "                x1,\n",
    "                x2,\n",
    "                x1 * x2,\n",
    "                x1**2,\n",
    "                x2**2,\n",
    "                x1**3,\n",
    "                x1**2 * x2,\n",
    "                x1 * x2**2,\n",
    "                x2**3\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Monomial basis with nb_expl_vars={nb_expl_vars} not supported\"\n",
    "            )\n",
    "\n",
    "    elif basis == 2:\n",
    "        # —— Chebyshev basis ——\n",
    "        if nb_expl_vars == 6:\n",
    "            # order ≤2 Chebyshev: T_i(x)T_j(y), i+j≤2\n",
    "            X[i, :] = np.array([\n",
    "                1,                   # T0(x)T0(y)\n",
    "                x1,                  # T1(x)T0(y)\n",
    "                x2,                  # T0(x)T1(y)\n",
    "                x1 * x2,             # T1(x)T1(y)\n",
    "                (x1**2 - 1),         # T2(x)T0(y)\n",
    "                (x2**2 - 1)          # T0(x)T2(y)\n",
    "            ])\n",
    "        elif nb_expl_vars == 10:\n",
    "            # order ≤3 Chebyshev: T_i(x)T_j(y), i+j≤3\n",
    "            X[i, :] = np.array([\n",
    "                1,                     # T0(x)T0(y)\n",
    "                x1,                    # T1(x)T0(y)\n",
    "                x2,                    # T0(x)T1(y)\n",
    "                x1 * x2,               # T1(x)T1(y)\n",
    "                (x1**2 - 1),           # T2(x)T0(y)\n",
    "                (x2**2 - 1),           # T0(x)T2(y)\n",
    "                (4*x1**3 - 3*x1),      # T3(x)T0(y)\n",
    "                (4*x2**3 - 3*x2),      # T0(x)T3(y)\n",
    "                (x1**2 - 1) * x2,      # T2(x)T1(y)\n",
    "                x1 * (x2**2 - 1)       # T1(x)T2(y)\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Chebyshev basis with nb_expl_vars={nb_expl_vars} not supported\"\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown basis={basis}; must be 1 or 2\")\n",
    "\n",
    "def build_design_matrix(x1, x2, nb_expl_vars, basis):\n",
    "    \"\"\"\n",
    "    Build the full design matrix X for vectors x1, x2 of length n,\n",
    "    using either a monomial basis (basis=1) or Chebyshev basis (basis=2),\n",
    "    with either 4, 6 or 10 regressors (nb_expl_vars).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray, shape (n, nb_expl_vars)\n",
    "    \"\"\"\n",
    "    n = len(x1)\n",
    "    X = np.empty((n, nb_expl_vars))\n",
    "    for i in range(n):\n",
    "        fill_X_row(X, i, x1[i], x2[i], nb_expl_vars, basis)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce0bbe-a0a7-41dd-90a5-a78db35a511b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c3ce0bbe-a0a7-41dd-90a5-a78db35a511b",
    "outputId": "db846fb9-43ac-405a-ce44-fbb41aadc6b4"
   },
   "outputs": [],
   "source": [
    "# Usual PEA\n",
    "tol = 1e-6\n",
    "gam = 1.0\n",
    "init = 100 #burnin\n",
    "long = 50000\n",
    "slong = init + long\n",
    "\n",
    "# SS value. Use mean values on the simulation\n",
    "k_ss = SS_values[SS_values[\"Variable\"] == \"k\"][\"MeanValue\"].item()\n",
    "a_ss = 0\n",
    "c_ss = SS_values[SS_values[\"Variable\"] == \"c\"][\"MeanValue\"].item()\n",
    "\n",
    "# Indexes\n",
    "T = np.arange(init, slong-1)      \n",
    "T1 = np.arange(init+1, slong)    \n",
    "\n",
    "# Compute initial conditions:\n",
    "print(f\"Intial b0: {coeff_array_0}\")\n",
    "b0 = coeff_array_0\n",
    "\n",
    "# Generate shocks: e is a vector of size slong with normally distributed shocks scaled by se\n",
    "e = params.std_tfp * np.random.randn(slong)\n",
    "\n",
    "# Initialize a as a vector of zeros\n",
    "a = np.zeros(slong)\n",
    "\n",
    "# Set the first element of a\n",
    "a[0] = a_ss\n",
    "\n",
    "# Generate the AR(1) process for a\n",
    "for i in range(1, slong):\n",
    "    a[i] = params.rho_tfp * a[i-1] + e[i]\n",
    "\n",
    "# Initialize iteration counter and convergence criterion\n",
    "iteration = 1\n",
    "crit = np.inf  # set to a large number initially\n",
    "\n",
    "while crit > tol:\n",
    "#while iteration < 10:\n",
    "    k = np.zeros(slong + 1)\n",
    "    c = np.zeros(slong)\n",
    "    X = np.zeros((slong, len(b0)))\n",
    "    cash = np.zeros(slong)\n",
    "\n",
    "    # Set initial capital:\n",
    "    k[0] = k_ss\n",
    "\n",
    "    # Simulate the path:\n",
    "    for i in range(slong):\n",
    "        # Construct the regressors at time i.\n",
    "        if (params.center_dep_var == True) & (params.normalize_dep_var == True):\n",
    "            x1 = (k[i] - params.kss)/params.std_k\n",
    "            x2 = a[i]/params.std_a\n",
    "        elif (params.center_dep_var == True) & (params.normalize_dep_var == False):\n",
    "            x1 = (k[i] - params.kss)\n",
    "            x2 = a[i]\n",
    "        else:\n",
    "            x1 = np.log(k[i])\n",
    "            x2 = a[i]\n",
    "\n",
    "        # Set values fo X:\n",
    "        fill_X_row(X, i, x1, x2, params.nb_expl_vars, params.basis)\n",
    "        \n",
    "        # Cash on hand\n",
    "        cash[i] = np.exp(a[i]) * (k[i]**params.alpha) + (1 - params.delta) * k[i]\n",
    "\n",
    "        # Update capital for the next period using the model's law of motion\n",
    "        if cond_exp_chosen == 2:\n",
    "            c[i] = params.css*np.maximum(params.tol_c, np.dot(X[i, :], b0))**(-1/params.gamma)\n",
    "            c[i] = np.maximum(params.tol_c, c[i])\n",
    "            k[i+1] = np.maximum(cash[i] - c[i], params.tol_c)\n",
    "        elif cond_exp_chosen == 5:\n",
    "            k[i+1] = np.maximum(np.dot(X[i, :], b0), params.tol_c)\n",
    "            c[i] = np.maximum(params.tol_c, cash[i] - k[i+1])\n",
    "        elif cond_exp_chosen == 6:\n",
    "            y = np.dot(X[i, :], b0)\n",
    "            c[i] = params.css*(1 + y)**(-1/params.gamma)\n",
    "            c[i] = np.maximum(params.tol_c, c[i])\n",
    "            k[i+1] = np.maximum(cash[i] - c[i], params.tol_c)\n",
    "        elif cond_exp_chosen == 7:\n",
    "            c[i] = np.exp(np.dot(X[i, :], b0))**(-1/params.gamma)\n",
    "            k[i+1] = np.maximum(cash[i] - c[i], params.tol_c)\n",
    "        else:\n",
    "            print(f\"cond_exp_chosen : {cond_exp_chosen} not implemented yet)\")\n",
    "    # Construct the vector y using the simulated paths (vectorized operation)\n",
    "    if cond_exp_chosen == 2:\n",
    "        y = params.beta * ( (c[T1]/params.css)**(-params.gamma) ) * (params.alpha * np.exp(a[T1]) * k[T1]**(params.alpha - 1) + 1 - params.delta)\n",
    "    elif cond_exp_chosen == 5:\n",
    "        y = params.beta * (k[T1]) * ( (c[T1]/c[T])**(-params.gamma) ) * (params.alpha * np.exp(a[T1]) * k[T1]**(params.alpha - 1) + 1 - params.delta)\n",
    "    elif cond_exp_chosen == 6:\n",
    "        y = params.beta * ( (c[T1]/params.css)**(-params.gamma) ) * (params.alpha * np.exp(a[T1]) * k[T1]**(params.alpha - 1) + 1 - params.delta) - 1\n",
    "    elif cond_exp_chosen == 7:\n",
    "        y = np.log( params.beta * ( ( c[T1] ) ** ( -params.gamma ) ) * (params.alpha * np.exp(a[T1]) * k[T1]**(params.alpha - 1) + 1 - params.delta) )\n",
    "    \n",
    "    # Solve the regression: log(y) = X(T,:) * bt in a least-squares sense.\n",
    "    # np.linalg.lstsq returns a tuple; the first element is the solution.\n",
    "    y_reg = y\n",
    "    X_reg = X[T, :]\n",
    "    bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)\n",
    "\n",
    "    if params.regression_two_steps == True:\n",
    "        print(f\"Step 1 coef: {bt}\")\n",
    "        # Square root of weights, when using log model\n",
    "        sqrt_w = np.exp(X_reg @ bt)\n",
    "        # Pre-multiply and then regress again\n",
    "        X_wls = X_reg * sqrt_w[:, None]\n",
    "        y_wls = y_reg * sqrt_w\n",
    "        bt, _, _, _ = np.linalg.lstsq(X_wls, y_wls, rcond=None)\n",
    "        print(f\"Step 2 coef: {bt}\")\n",
    "    elif params.feasible_GLS == True:\n",
    "        print(f\"Step 1 coef: {bt}\")\n",
    "        ## residuals\n",
    "        e0 = y_reg - X_reg @ bt\n",
    "        # Estimate the variance‐function via a log‐linear model\n",
    "        # use X_reg as Z, but you can build a richer Z = f(state)\n",
    "        Z = X_reg\n",
    "        # add tiny constant to avoid log(0)\n",
    "        log_u = np.log(e0**2 + 1e-12)                    \n",
    "        gamma, *_ = np.linalg.lstsq(Z, log_u, rcond=None)\n",
    "        # fitted log‐variance and variance estimate\n",
    "        log_var_hat = Z @ gamma          # E[log(e^2)|Z]\n",
    "        var_hat     = np.exp(log_var_hat)  # ≈ Var(e_m) * N\n",
    "        # Construct inverse‐variance weights and do WLS\n",
    "        w       = 1.0 / var_hat        \n",
    "        sqrt_w  = np.sqrt(w)\n",
    "        # Pre-multiply and then regress again\n",
    "        X_wls = X_reg * sqrt_w[:, None]\n",
    "        y_wls = y_reg * sqrt_w\n",
    "        bt, _, _, _ = np.linalg.lstsq(X_wls, y_wls, rcond=None)\n",
    "        print(f\"Step 2 coef FGLS: {bt}\")\n",
    "    \n",
    "    # Update b using a smoothing parameter gam:\n",
    "    b = gam * bt + (1 - gam) * b0\n",
    "\n",
    "    # Compute convergence criterion (maximum absolute change in b)\n",
    "    crit = np.max(np.abs(b - b0))\n",
    "\n",
    "    # Update b0 for the next iteration\n",
    "    b0 = b.copy()\n",
    "\n",
    "    # Display current iteration and convergence criterion\n",
    "    print(f\"Iteration: {iteration}\\tConv. crit.: {crit}\\t b: {b}\")\n",
    "\n",
    "    iteration += 1\n",
    "\n",
    "# residual\n",
    "Res = y_reg - np.dot(X[T, :], b0)\n",
    "MSE = np.mean(Res ** 2)\n",
    "\n",
    "# =============================================================================\n",
    "# Plotting results\n",
    "# =============================================================================\n",
    "# 1. Plot histogram of residuals\n",
    "plt.figure()\n",
    "plt.hist(Res, bins=100)\n",
    "plt.title('Residuals', fontname='Times', fontsize=12)\n",
    "\n",
    "# 2. Compute investment deviations: it = k[T1] - (1-delta)*k[T]\n",
    "it = k[T1] - (1 - params.delta) * k[T]\n",
    "\n",
    "# Create a 2x2 figure for several plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Investment scatter plot\n",
    "axs[0, 0].plot(k[T], it, '.', markersize=0.5, color='k')\n",
    "axs[0, 0].set_xlabel('k_t', fontname='Times', fontsize=12)\n",
    "axs[0, 0].set_title('Investment', fontname='Times', fontsize=12)\n",
    "\n",
    "# Histogram of investment\n",
    "axs[0, 1].hist(it, bins=100)\n",
    "axs[0, 1].set_title('Distribution of Investment', fontname='Times', fontsize=12)\n",
    "\n",
    "# Capital stock: plot k[T] vs. k[T1] and add 45° reference line (scaled by (1-delta))\n",
    "axs[1, 0].plot(k[T], k[T1], '.', markersize=0.5, color='k')\n",
    "x_line = np.linspace(np.min(k[T]), np.max(k[T]), 100)\n",
    "axs[1, 0].plot(x_line, (1 - params.delta) * x_line, '-', linewidth=1.2, color='g')\n",
    "axs[1, 0].set_xlabel('k_t', fontname='Times', fontsize=12)\n",
    "axs[1, 0].set_title('Capital Stock', fontname='Times', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# 3. Time series plots for a subset (T0 = 500:1000)\n",
    "T0 = np.arange(500, 1000)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "ax.plot(it[T0], 'k')\n",
    "ax.set_xlabel('Time', fontname='Times', fontsize=12)\n",
    "ax.set_title('Investment', fontname='Times', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "percentage_negative_investment = len(it[it < 0])/len(it)\n",
    "print(f\"Percentage of time negative investment: {percentage_negative_investment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793211f-f028-4975-831e-478346d4d0a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "1793211f-f028-4975-831e-478346d4d0a5",
    "outputId": "193c44af-27cc-4396-d548-c37dd08c06ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(k[:-1], k[1:])\n",
    "plt.plot(k[1:], k[1:], linestyle=\"--\", color = \"k\")\n",
    "plt.ylabel(\"kt+1\")\n",
    "plt.xlabel(\"kt\")\n",
    "plt.savefig(output_folder + \"kt_kt1.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0fe5c-3f8d-474e-9047-e9ff66b61bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_k_a(k, a):\n",
    "    \"\"\"\n",
    "    Compute basic summary statistics for two variables k and a.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : array-like\n",
    "        Numerical data for variable k.\n",
    "    a : array-like\n",
    "        Numerical data for variable a.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary_df : pandas.DataFrame\n",
    "        DataFrame with rows ['k','a'] and columns ['Mean','Median','Std','Min','Max'].\n",
    "    \"\"\"\n",
    "    # ensure numpy arrays\n",
    "    k = np.asarray(k)\n",
    "    a = np.asarray(a)\n",
    "\n",
    "    stats_dict = {\n",
    "        'Variable': ['k', 'a'],\n",
    "        'Mean'    : [k.mean(),      a.mean()],\n",
    "        'Median'  : [np.median(k),  np.median(a)],\n",
    "        'Std'     : [k.std(),       a.std()],\n",
    "        'Min'     : [k.min(),       a.min()],\n",
    "        'Max'     : [k.max(),       a.max()],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(stats_dict)\n",
    "    return summary_df\n",
    "    \n",
    "def plot_consumption_slices_non_binding(params,\n",
    "                            mean_k, std_k,\n",
    "                            a_ss, std_a,\n",
    "                            b0, coeff_array_0,\n",
    "                            cond_exp_chosen,\n",
    "                            nb_stdev=2,\n",
    "                            nb_points=500):\n",
    "    \"\"\"\n",
    "    Plot optimal consumption slices along k and a. Model without constraint on investment.\n",
    "\n",
    "    params: object with attributes\n",
    "        - center_dep_var (bool)\n",
    "        - normalize_dep_var (bool)\n",
    "        - kss, std_k, std_a\n",
    "        - alpha, delta, gamma, css, tol_c\n",
    "        - nb_expl_vars (int), basis (int)\n",
    "    mean_k, std_k: float\n",
    "    a_ss, std_a: float\n",
    "    b0, coeff_array_0: arrays of regression coefficients\n",
    "    cond_exp_chosen: int (2, 5, 6, or 7)\n",
    "    nb_stdev: number of standard deviations to plot around the mean\n",
    "    nb_points: number of grid points per slice\n",
    "    \"\"\"\n",
    "    # Create subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    for i, var in enumerate([\"k\", \"a\"]):\n",
    "        # build grids\n",
    "        if var == \"k\":\n",
    "            k_grid = np.linspace(mean_k - nb_stdev*std_k,\n",
    "                                 mean_k + nb_stdev*std_k,\n",
    "                                 nb_points)\n",
    "            a_grid = a_ss * np.ones_like(k_grid)\n",
    "        else:\n",
    "            a_grid = np.linspace(a_ss - nb_stdev*std_a,\n",
    "                                 a_ss + nb_stdev*std_a,\n",
    "                                 nb_points)\n",
    "            k_grid = mean_k * np.ones_like(a_grid)\n",
    "\n",
    "        # transform explanatory variables\n",
    "        if params.center_dep_var and params.normalize_dep_var:\n",
    "            x1 = (k_grid - params.kss) / params.std_k\n",
    "            x2 = a_grid / params.std_a\n",
    "        elif params.center_dep_var and not params.normalize_dep_var:\n",
    "            x1 = (k_grid - params.kss)\n",
    "            x2 = a_grid\n",
    "        else:\n",
    "            x1 = np.log(k_grid)\n",
    "            x2 = a_grid\n",
    "\n",
    "        # construct design matrix X\n",
    "        X = build_design_matrix(x1, x2, nb_expl_vars=params.nb_expl_vars, basis=params.basis)\n",
    "\n",
    "        # cash-on-hand\n",
    "        cash = np.exp(a_grid)*k_grid**params.alpha + (1 - params.delta)*k_grid\n",
    "\n",
    "        # compute consumption and (if needed) k_next under different conditional expectations\n",
    "        if cond_exp_chosen == 2:\n",
    "            c_pea = params.css * np.maximum(1e-2, X.dot(b0))**(-1/params.gamma)\n",
    "            c_pea = np.clip(c_pea, params.tol_c, cash - params.tol_c)\n",
    "            c0 = params.css * np.maximum(1e-2, X.dot(coeff_array_0))**(-1/params.gamma)\n",
    "            c0 = np.clip(c0, params.tol_c, cash - params.tol_c)\n",
    "\n",
    "        elif cond_exp_chosen == 5:\n",
    "            k_next = X.dot(b0)\n",
    "            c_pea = np.maximum(cash - k_next, params.tol_c)\n",
    "            c0 = np.maximum(cash - X.dot(coeff_array_0), params.tol_c)\n",
    "\n",
    "        elif cond_exp_chosen == 6:\n",
    "            c_pea = params.css * (1 + X.dot(b0))**(-1/params.gamma)\n",
    "            c_pea = np.maximum(c_pea, params.tol_c)\n",
    "            k_next = np.maximum(cash - c_pea, params.tol_c)\n",
    "\n",
    "            c0 = params.css * (1 + X.dot(coeff_array_0))**(-1/params.gamma)\n",
    "            c0 = np.maximum(c0, params.tol_c)\n",
    "\n",
    "        elif cond_exp_chosen == 7:\n",
    "            c_pea = np.exp(X.dot(b0))**(-1/params.gamma)\n",
    "            c0 = np.exp(X.dot(coeff_array_0))**(-1/params.gamma)\n",
    "            k_next = np.maximum(cash - c_pea, params.tol_c)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"cond_exp_chosen={cond_exp_chosen} not implemented\")\n",
    "\n",
    "        # plot\n",
    "        grid = k_grid if var == \"k\" else a_grid\n",
    "        xlabel = 'Capital, k' if var == \"k\" else 'tpf, a'\n",
    "        axs[i].plot(grid, c_pea, label=\"PEA\")\n",
    "        axs[i].plot(grid, c0,   label=\"Initial guess\")\n",
    "        axs[i].set_xlabel(xlabel)\n",
    "        axs[i].set_ylabel('Consumption, c')\n",
    "        axs[i].set_title(f'Optimal Consumption (slice along {var})')\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    axs[1].legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_stats = summarize_k_a(k, a)\n",
    "print(df_stats)\n",
    "\n",
    "plot_consumption_slices_non_binding(\n",
    "    params,\n",
    "    mean_k=df_stats[df_stats[\"Variable\"] == \"k\"][\"Mean\"].item(), \n",
    "    std_k=df_stats[df_stats[\"Variable\"] == \"k\"][\"Std\"].item(),\n",
    "    a_ss=0.0,   \n",
    "    std_a=params.std_a,\n",
    "    b0=b0, \n",
    "    coeff_array_0=coeff_array_0,\n",
    "    cond_exp_chosen=7,\n",
    "    nb_stdev=2,\n",
    "    nb_points=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452fde84-4235-45a8-a948-3abcef1c8e22",
   "metadata": {
    "id": "452fde84-4235-45a8-a948-3abcef1c8e22"
   },
   "source": [
    "### II.C. Solving model with irreversible investment constraints\n",
    "\n",
    "#### II.C.1. Usual PEA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b3c05-6dd9-4d3d-8e37-b90faeb95ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhm_accuracy_test(params, b0, e_test, init = 1000):\n",
    "    \"\"\"\n",
    "    Compute the DHM accuracy test for a given set of parameters and an initial coefficient vector b0.\n",
    "\n",
    "    Parameters:\n",
    "    params: Instance containing model parameters (beta, delta, alpha, gamma, rho_tfp, std_tfp)\n",
    "    b0: Coefficient vector used for the approximation.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing DHM test results.\n",
    "    \"\"\"\n",
    "    # Simulation setup\n",
    "    slong = len(e_test) #init + long\n",
    "    long = slong - init\n",
    "    if long <= 0:\n",
    "        raise Exception(f\"long is :{long}. Increase length of e_test, or decrease init\") \n",
    "\n",
    "    T = np.arange(init, slong - 2)  # Select current period\n",
    "    T1 = np.arange(init + 1, slong - 1) # Select period t+1. Drop last period, for which mu is not calculated\n",
    "\n",
    "    # Generate shocks and AR(1) process for a\n",
    "    a = np.zeros(slong)\n",
    "    for i in range(1, slong):\n",
    "        a[i] = params.rho_tfp * a[i - 1] + e_test[i]\n",
    "\n",
    "    # Initialize variables\n",
    "    k = np.zeros(slong + 1)\n",
    "    mu =  np.zeros(slong + 1) #lagrange multiplier\n",
    "    c = np.zeros(slong)\n",
    "    production = np.zeros(slong)\n",
    "    inv = np.zeros(slong) #investment\n",
    "    cash = np.zeros(slong)\n",
    "    X = np.zeros((slong, len(b0)))\n",
    "    k[0] = params.kss  # Initial capital at steady state\n",
    "\n",
    "          \n",
    "    # Upper bound on E_t\n",
    "    E_max = params.tol_c**(-params.gamma)            # ensures c >= tol_c\n",
    "\n",
    "    # Simulate the economy\n",
    "    for i in range(slong):\n",
    "        if (params.center_dep_var == True) & (params.normalize_dep_var == True):\n",
    "            x1 = (k[i] - params.kss)/params.std_k\n",
    "            x2 = a[i]/params.std_a\n",
    "        elif (params.center_dep_var == True) & (params.normalize_dep_var == False):\n",
    "            x1 = (k[i] - params.kss)\n",
    "            x2 = a[i]\n",
    "        else:\n",
    "            x1 = np.log(k[i])\n",
    "            x2 = a[i]\n",
    "\n",
    "        # Set values fo X:\n",
    "        fill_X_row(X, i, x1, x2, params.nb_expl_vars, params.basis)\n",
    "\n",
    "        production[i] = np.exp(a[i]) * k[i]**params.alpha\n",
    "        cash[i] = production[i] + (1 - params.delta) * k[i]\n",
    "\n",
    "        # Consumption, assuming current constraint on investment does not bind\n",
    "        #E_t_tilde = np.clip(np.exp(np.dot(X[i, :], b0)), production[i]**(-params.gamma), E_max)    \n",
    "        E_t_tilde = np.exp(np.dot(X[i, :], b0))\n",
    "        c[i] = E_t_tilde ** (-1/params.gamma)\n",
    "        \n",
    "        # Update guess, after calculating investmen\n",
    "        inv[i] = production[i] - c[i]\n",
    "        if inv[i] > 0:\n",
    "            k[i+1] = cash[i] - c[i]\n",
    "        else:\n",
    "            k[i+1] = (1 - params.delta) * k[i]\n",
    "            c[i] = production[i]\n",
    "            mu[i] = c[i]**( - params.gamma ) - E_t_tilde\n",
    "\n",
    "    # Compute the error term\n",
    "    ut = c[T]**(-params.gamma) - mu[T] - params.beta * ( ( c[T1]**(-params.gamma) ) * (params.alpha * np.exp(a[T1]) * k[T1] ** (params.alpha - 1) + 1 - params.delta) + mu[T1] * ( 1 - params.delta) )\n",
    "    \n",
    "    # Compute DHM statistics\n",
    "    mean_ut = np.mean(ut)\n",
    "    mean_abs_ut = np.mean(np.abs(ut))\n",
    "    mean_square_ut = np.mean(ut**2)\n",
    "    var_ut = np.var(ut, ddof=1)\n",
    "    std_ut = np.sqrt(var_ut)\n",
    "    T_sample = len(ut)\n",
    "    dhm_stat = T_sample * (mean_ut ** 2) / var_ut\n",
    "\n",
    "    # Chi-square critical values\n",
    "    lower5 = chi2.ppf(0.05, df=1)\n",
    "    upper5 = chi2.ppf(0.95, df=1)\n",
    "\n",
    "    # Compute consumption equivalent\n",
    "    mean_k = np.mean(k)\n",
    "    a_ss = 0\n",
    "\n",
    "    if (params.center_dep_var == True) & (params.normalize_dep_var == True):\n",
    "        x1 = (mean_k - params.kss)/params.std_k\n",
    "        x2 = a_ss/params.std_a\n",
    "    elif (params.center_dep_var == True) & (params.normalize_dep_var == False):\n",
    "        x1 = (mean_k - params.kss)\n",
    "        x2 = a_ss\n",
    "    else:\n",
    "        x1 = np.log(mean_k)\n",
    "        x2 = a_ss\n",
    "\n",
    "    # Build X_ss\n",
    "    X_ss = build_design_matrix(np.atleast_1d(x1), np.atleast_1d(x2), nb_expl_vars=params.nb_expl_vars, basis=params.basis)\n",
    "    \n",
    "    # Consumption at the non-stochastic ss:\n",
    "    ## (assuming constraint does not bind):\n",
    "    c_ss = np.exp(np.dot(X_ss, b0)) ** (-1/params.gamma)\n",
    "        \n",
    "    c_diff = (mean_ut + c_ss ** (-params.gamma)) ** (-1 / params.gamma)\n",
    "    #c_diff = (mean_abs_ut + c_ss ** (-params.gamma)) ** (-1 / params.gamma)\n",
    "    c_equivalent = 100 * (c_diff - c_ss) / c_ss\n",
    "\n",
    "    return mean_abs_ut,  mean_square_ut, std_ut, dhm_stat, c_equivalent\n",
    "\n",
    "\n",
    "def plot_consumption_slices(params,\n",
    "                            mean_k, std_k,\n",
    "                            a_ss, std_a,\n",
    "                            b0, coeff_array_0,\n",
    "                            cond_exp_chosen,\n",
    "                            nb_stdev=2,\n",
    "                            nb_points=500):\n",
    "    \"\"\"\n",
    "    Plot optimal consumption slices along k and a. Model with constraint on investment.\n",
    "\n",
    "    params: object with attributes\n",
    "        - center_dep_var (bool)\n",
    "        - normalize_dep_var (bool)\n",
    "        - kss, std_k, std_a\n",
    "        - alpha, delta, gamma, css, tol_c\n",
    "        - nb_expl_vars (int), basis (int)\n",
    "    mean_k, std_k: float\n",
    "    a_ss, std_a: float\n",
    "    b0, coeff_array_0: arrays of regression coefficients\n",
    "    cond_exp_chosen: int (2, 5, 6, or 7)\n",
    "    nb_stdev: number of standard deviations to plot around the mean\n",
    "    nb_points: number of grid points per slice\n",
    "    \"\"\"\n",
    "    if cond_exp_chosen != 7:\n",
    "        raise NotImplementedError(f\"cond_exp_chosen={cond_exp_chosen} not implemented\")\n",
    "        \n",
    "    # Create subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    for i, var in enumerate([\"k\", \"a\"]):\n",
    "        # build grids\n",
    "        if var == \"k\":\n",
    "            k_grid = np.linspace(mean_k - nb_stdev*std_k,\n",
    "                                 mean_k + nb_stdev*std_k,\n",
    "                                 nb_points)\n",
    "            a_grid = a_ss * np.ones_like(k_grid)\n",
    "        else:\n",
    "            a_grid = np.linspace(a_ss - nb_stdev*std_a,\n",
    "                                 a_ss + nb_stdev*std_a,\n",
    "                                 nb_points)\n",
    "            k_grid = mean_k * np.ones_like(a_grid)\n",
    "\n",
    "        # transform explanatory variables\n",
    "        if params.center_dep_var and params.normalize_dep_var:\n",
    "            x1 = (k_grid - params.kss) / params.std_k\n",
    "            x2 = a_grid / params.std_a\n",
    "        elif params.center_dep_var and not params.normalize_dep_var:\n",
    "            x1 = (k_grid - params.kss)\n",
    "            x2 = a_grid\n",
    "        else:\n",
    "            x1 = np.log(k_grid)\n",
    "            x2 = a_grid\n",
    "\n",
    "        # construct design matrix X\n",
    "        X = build_design_matrix(x1, x2, nb_expl_vars=params.nb_expl_vars, basis=params.basis)\n",
    "        \n",
    "        # producton\n",
    "        production = np.exp(a_grid)*k_grid**params.alpha\n",
    "        # cash-on-hand\n",
    "        cash = production + (1 - params.delta)*k_grid\n",
    "\n",
    "        # Consumption, assuming current constraint on investment does not bind:\n",
    "        ## With b0\n",
    "        E_pea = np.exp(X.dot(b0))\n",
    "        c_pea = E_pea**(-1/params.gamma)\n",
    "        \n",
    "        # Update guess, after calculating investment\n",
    "        inv = production - c_pea\n",
    "\n",
    "        k_next = np.where(inv > 0, cash - c_pea, (1 - params.delta) * k_grid)\n",
    "        c_pea = np.where(inv > 0, c_pea,  production)\n",
    "        mu = np.where(inv > 0, 0.0,  c_pea ** ( - params.gamma ) - E_pea)\n",
    "        \n",
    "        ## With \n",
    "        E_0 = np.exp(X.dot(coeff_array_0))\n",
    "        c_0 = E_0**(-1/params.gamma)\n",
    "\n",
    "        inv_0 = production - c_0\n",
    "        k_next_0 = np.where(inv_0 > 0, cash - c_0, (1 - params.delta) * k_grid)\n",
    "        c_0 = np.where(inv_0 > 0, c_0,  production)\n",
    "        mu_0 = np.where(inv_0 > 0, 0.0,  c_0 ** ( - params.gamma ) - E_0)\n",
    "        \n",
    "            \n",
    "        # plot\n",
    "        grid = k_grid if var == \"k\" else a_grid\n",
    "        xlabel = 'Capital, k' if var == \"k\" else 'tpf, a'\n",
    "        axs[i].plot(grid, c_pea, label=\"PEA\")\n",
    "        axs[i].plot(grid, c_0,   label=\"Initial guess\")\n",
    "        axs[i].set_xlabel(xlabel)\n",
    "        axs[i].set_ylabel('Consumption, c')\n",
    "        axs[i].set_title(f'Optimal Consumption (slice along {var})')\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    axs[1].legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd4366-9666-4d83-ac46-6f03aef07750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Nice typography without requiring a LaTeX install ---\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.serif'] = ['Times']\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'   # math font close to Time\n",
    "\n",
    "# Usual PEA\n",
    "tol = 1e-6\n",
    "gam = 1.0\n",
    "init = 100 #burnin\n",
    "\n",
    "results_standard_PEA = []\n",
    "slong_test = 200000\n",
    "e_test = params.std_tfp * np.random.randn(slong_test)\n",
    "\n",
    "max_iter = 30\n",
    "\n",
    "# Try for different number of state draws:\n",
    "for long in [1000, 10000, 50000, 100000]:\n",
    "    slong = init + long\n",
    "    print(f\"State vector draws: {long}\")\n",
    "    \n",
    "    # SS value. Use mean values on the simulation\n",
    "    k_ss = SS_values[SS_values[\"Variable\"] == \"k\"][\"MeanValue\"].item()\n",
    "    a_ss = 0\n",
    "    c_ss = SS_values[SS_values[\"Variable\"] == \"c\"][\"MeanValue\"].item()\n",
    "\n",
    "    # To ensure consumption is a least tol_c\n",
    "    E_max = params.tol_c**(-params.gamma)\n",
    "    \n",
    "    # Also, define the index arrays T and T1\n",
    "    T = np.arange(init, slong-2) # current period\n",
    "    T1 = np.arange(init+1, slong-1) # forward by one period. Drop last period, for which mu is not calculated\n",
    "    \n",
    "    # Compute initial conditions:\n",
    "    print(f\"Intial b0: {coeff_array_0}\")\n",
    "    b0 = coeff_array_0.copy()\n",
    "    \n",
    "    # Generate shocks: e is a vector of size slong with normally distributed shocks scaled by se\n",
    "    e = params.std_tfp * np.random.randn(slong)\n",
    "    \n",
    "    # Initialize a as a vector of zeros\n",
    "    a = np.zeros(slong)\n",
    "    \n",
    "    # Set the first element of a\n",
    "    a[0] = a_ss\n",
    "    \n",
    "    # Generate the AR(1) process for a\n",
    "    for i in range(1, slong):\n",
    "        a[i] = params.rho_tfp * a[i-1] + e[i]\n",
    "    \n",
    "    # Initialize iteration counter and convergence criterion\n",
    "    iteration = 1\n",
    "    crit = np.inf  # set to a large number initially\n",
    "    \n",
    "    #while crit > tol:\n",
    "    while iteration < max_iter :\n",
    "        k = np.zeros(slong + 1)\n",
    "        c = np.zeros(slong)\n",
    "        inv = np.zeros(slong)\n",
    "        production = np.zeros(slong)\n",
    "        X = np.zeros((slong, len(b0)))\n",
    "        cash = np.zeros(slong)\n",
    "        mu = np.zeros(slong + 1) #Lagrange multiplier\n",
    "        \n",
    "        # Set initial capital:\n",
    "        k[0] = k_ss\n",
    "    \n",
    "        # Simulate the path:\n",
    "        for i in range(slong):\n",
    "            # Construct the regressors at time i.\n",
    "            if (params.center_dep_var == True) & (params.normalize_dep_var == True):\n",
    "                x1 = (k[i] - params.kss)/params.std_k\n",
    "                x2 = a[i]/params.std_a\n",
    "            elif (params.center_dep_var == True) & (params.normalize_dep_var == False):\n",
    "                x1 = (k[i] - params.kss)\n",
    "                x2 = a[i]\n",
    "            else:\n",
    "                x1 = np.log(k[i])\n",
    "                x2 = a[i]\n",
    "\n",
    "            fill_X_row(X, i, x1, x2, params.nb_expl_vars, params.basis)\n",
    "            \n",
    "            # Ouptut\n",
    "            production[i] = np.exp(a[i]) * (k[i]**params.alpha)\n",
    "            # Cash on hand: production + capital from last period\n",
    "            cash[i] =  production[i] + (1 - params.delta) * k[i]\n",
    "    \n",
    "            # Update capital for the next period using the model's law of motion\n",
    "            # Consumption, assuming current constraint on investment does not bind\n",
    "            if cond_exp_chosen == 7:\n",
    "                #E_t_tilde = np.clip(np.exp(np.dot(X[i, :], b0)), production[i]**(-params.gamma), E_max)  \n",
    "                E_t_tilde = np.exp(np.dot(X[i, :], b0))\n",
    "                c[i] = E_t_tilde ** (-1/params.gamma)\n",
    "            else:\n",
    "                print(f\"cond_exp_chosen : {cond_exp_chosen} not implemented yet)\")\n",
    "    \n",
    "            # Update guess, after calculating investmen\n",
    "            inv[i] = production[i] - c[i]\n",
    "            if inv[i] > 0:\n",
    "                k[i+1] = cash[i] - c[i]\n",
    "            else:\n",
    "                k[i+1] = (1 - params.delta) * k[i]\n",
    "                c[i] = production[i]\n",
    "                mu[i] = c[i]**( - params.gamma ) - E_t_tilde\n",
    "    \n",
    "        # Construct the vector y using the simulated paths (vectorized operation)\n",
    "        if cond_exp_chosen == 7:\n",
    "            y = np.log(params.beta * ( ( c[T1]**(-params.gamma) ) * (params.alpha * np.exp(a[T1]) * k[T1] ** (params.alpha - 1) + 1 - params.delta) + mu[T1] * ( 1 - params.delta) ) )\n",
    "\n",
    "        # Solve the regression: log(y) = X(T,:) * bt in a least-squares sense.\n",
    "        # np.linalg.lstsq returns a tuple; the first element is the solution.\n",
    "        y_reg = y\n",
    "        X_reg = X[T, :]\n",
    "        bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)\n",
    "\n",
    "        if params.regression_two_steps == True:\n",
    "            #print(f\"Step 1 coef: {bt}\")\n",
    "            # Square root of weights, when using log model\n",
    "            sqrt_w = np.exp(X_reg @ bt)\n",
    "            # Pre-multiply and then regress again\n",
    "            X_wls = X_reg * sqrt_w[:, None]\n",
    "            y_wls = y_reg * sqrt_w\n",
    "            bt, _, _, _ = np.linalg.lstsq(X_wls, y_wls, rcond=None)\n",
    "            #print(f\"Step 2 coef: {bt}\")\n",
    "        elif params.feasible_GLS == True:\n",
    "            print(f\"Step 1 coef: {bt}\")\n",
    "            ## residuals\n",
    "            e0 = y_reg - X_reg @ bt\n",
    "            # Estimate the variance‐function via a log‐linear model\n",
    "            # use X_reg as Z, but you can build a richer Z = f(state)\n",
    "            Z = X_reg\n",
    "            # add tiny constant to avoid log(0)\n",
    "            log_u = np.log(e0**2 + 1e-12)                    \n",
    "            gamma, *_ = np.linalg.lstsq(Z, log_u, rcond=None)\n",
    "            # fitted log‐variance and variance estimate\n",
    "            log_var_hat = Z @ gamma          \n",
    "            var_hat     = np.exp(log_var_hat) \n",
    "            # Construct inverse‐variance weights and do WLS\n",
    "            w       = 1.0 / var_hat        \n",
    "            sqrt_w  = np.sqrt(w)\n",
    "            # Pre-multiply and then regress again\n",
    "            X_wls = X_reg * sqrt_w[:, None]\n",
    "            y_wls = y_reg * sqrt_w\n",
    "            bt, _, _, _ = np.linalg.lstsq(X_wls, y_wls, rcond=None)\n",
    "            print(f\"Step 2 coef FGLS: {bt}\")\n",
    "    \n",
    "        # Update b using a smoothing parameter gam:\n",
    "        b = gam * bt + (1 - gam) * b0\n",
    "    \n",
    "        # Compute convergence criterion (maximum absolute change in b)\n",
    "        crit = np.max(np.abs(b - b0))\n",
    "    \n",
    "        # Update b0 for the next iteration\n",
    "        b0 = b.copy()\n",
    "    \n",
    "        # Display current iteration and convergence criterion\n",
    "        if (iteration % 10 == 0):\n",
    "            print(f\"Iteration: {iteration}\\tConv. crit.: {crit}\\t b: {b}\")\n",
    "    \n",
    "        iteration += 1\n",
    "    \n",
    "    # residual\n",
    "    Res = y_reg - np.dot(X[T, :], b0)\n",
    "    MSE = np.mean(Res ** 2)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Plotting results\n",
    "    # =============================================================================\n",
    "    # 1. Plot histogram of residuals\n",
    "    plt.figure()\n",
    "    plt.hist(Res, bins=100)\n",
    "    plt.title('Residuals', fontname='Times', fontsize=12)\n",
    "    \n",
    "    # 2. Compute investment deviations: it = k[T1] - (1-delta)*k[T]\n",
    "    it = k[T1] - (1 - params.delta) * k[T]\n",
    "    \n",
    "    # Create a 2x2 figure for several plots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Investment scatter plot\n",
    "    axs[0, 0].plot(k[T], it, '.', markersize=0.5, color='k')\n",
    "    axs[0, 0].set_xlabel('k_t', fontname='Times', fontsize=12)\n",
    "    axs[0, 0].set_title('Investment', fontname='Times', fontsize=12)\n",
    "    \n",
    "    # Histogram of investment\n",
    "    axs[0, 1].hist(it, bins=100)\n",
    "    axs[0, 1].set_title('Distribution of Investment', fontname='Times', fontsize=12)\n",
    "    \n",
    "    # Capital stock: plot k[T] vs. k[T1] and add 45° reference line (scaled by (1-delta))\n",
    "    axs[1, 0].plot(k[T], k[T1], '.', markersize=0.5, color='k')\n",
    "    x_line = np.linspace(np.min(k[T]), np.max(k[T]), 100)\n",
    "    axs[1, 0].plot(x_line, (1 - params.delta) * x_line, '-', linewidth=1.2, color='g')\n",
    "    axs[1, 0].set_xlabel('k_t', fontname='Times', fontsize=12)\n",
    "    axs[1, 0].set_ylabel('k_t+1', fontname='Times', fontsize=12)\n",
    "    axs[1, 0].set_title('Capital Stock', fontname='Times', fontsize=12)\n",
    "    \n",
    "    # Lagrange multiplier\n",
    "    axs[1, 1].plot(k[T], mu[T], '.', markersize=0.5, color='k')\n",
    "    axs[1, 1].set_xlabel('k_t', fontname='Times', fontsize=12)\n",
    "    axs[1, 1].set_xlabel('mu_t', fontname='Times', fontsize=12)\n",
    "    axs[1, 1].set_title('Lagrange multiplier', fontname='Times', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 3. Time series plots for a subset\n",
    "    T0 = np.arange(100, 600)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].plot(it[T0], 'k')\n",
    "    axs[0].set_xlabel('Time', fontname='Times', fontsize=12)\n",
    "    axs[0].set_title('Investment', fontname='Times', fontsize=12)\n",
    "    \n",
    "    axs[1].plot(mu[T0], 'k')\n",
    "    axs[1].set_xlabel('Time', fontname='Times', fontsize=12)\n",
    "    axs[1].set_title('Lagrange multiplier', fontname='Times', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(output_folder + \"example_simlation_binding.pdf\", dpi=300)\n",
    "    \n",
    "    percentage_negative_investment = len(it[it < 0])/len(it)\n",
    "    print(f\"Percentage of time negative investment: {percentage_negative_investment}\")\n",
    "    \n",
    "    percentage_mu_binds = len(mu[mu > 0])/len(mu)\n",
    "    print(f\"Percentage mu binds: {percentage_mu_binds}\")\n",
    "    \n",
    "    mean_abs_ut, mean_square_ut, std_ut, dhm_stat, c_equivalent = dhm_accuracy_test(params, b0, e_test)\n",
    "    print(f\"Mean abs ut: {mean_abs_ut}, Mean square ut: {mean_square_ut}. DHM stats: {dhm_stat}. C equivalent: {c_equivalent}\")\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    results_standard_PEA.append({\n",
    "        \"k\": params.nb_expl_vars,\n",
    "        \"M\": long,\n",
    "        \"N\": 1,\n",
    "        \"DHM_stat\": dhm_stat,\n",
    "        \"C_equivalent\": c_equivalent,\n",
    "        \"MSE\": MSE})\n",
    "    \n",
    "    # Summary stats on k_t\n",
    "    df_stats = summarize_k_a(k, a)\n",
    "    print(df_stats)\n",
    "\n",
    "    # Slices around ss\n",
    "    plot_consumption_slices(\n",
    "                params,\n",
    "                mean_k=df_stats[df_stats[\"Variable\"] == \"k\"][\"Mean\"].item(), \n",
    "                std_k=df_stats[df_stats[\"Variable\"] == \"k\"][\"Std\"].item(),\n",
    "                a_ss=0.0,   \n",
    "                std_a=params.std_a,\n",
    "                b0=b0, \n",
    "                coeff_array_0=coeff_array_0,\n",
    "                cond_exp_chosen=7,\n",
    "                nb_stdev=2,\n",
    "                nb_points=1000)\n",
    "\n",
    "# Create a Pandas DataFrame from the results\n",
    "df_results_standard_PEA_M = pd.DataFrame(results_standard_PEA)\n",
    "df_results_standard_PEA_M.to_csv(output_folder + \"df_results_standard_PEA_M.csv\")\n",
    "print(df_results_standard_PEA_M.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c8f5f-235a-4e86-a237-c30cc291c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.serif'] = ['Times']\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'   # math close to Times\n",
    "\n",
    "# Indices for time-series panels\n",
    "T0 = np.arange(100, 600)\n",
    "\n",
    "# Build a 3×2 figure\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "(ax_a, ax_b), (ax_c, ax_d), (ax_e, ax_f) = axs\n",
    "\n",
    "# (1) Investment scatter: i_t vs k_t\n",
    "ax_a.plot(k[T], it, '.', markersize=0.5, color='k', rasterized=True)\n",
    "ax_a.set_xlabel(r'$k_t$', fontsize=12)\n",
    "ax_a.set_ylabel(r'$i_t$', fontsize=12)\n",
    "ax_a.set_title('Investment $i_t$', fontsize=12)\n",
    "\n",
    "# (2) Histogram of i_t\n",
    "ax_b.hist(it, bins=100)\n",
    "ax_b.set_xlabel(r'$i_t$', fontsize=12)\n",
    "ax_b.set_ylabel('Count', fontsize=12)\n",
    "ax_b.set_title(r'Distribution of $i_t$', fontsize=12)\n",
    "\n",
    "# (3) Capital stock: k_{t+1} vs k_t with reference line (1-δ)k_t\n",
    "\"\"\"\n",
    "ax_c.plot(k[T], k[T1], '.', markersize=0.5, color='k')\n",
    "x_line = np.linspace(np.min(k[T]), np.max(k[T]), 200)\n",
    "ax_c.plot(x_line, (1 - params.delta) * x_line, '-', linewidth=1.2, color='g',\n",
    "          label=rf'$(1-\\delta)\\,k_t$')\n",
    "ax_c.set_xlabel(r'$k_t$', fontsize=12)\n",
    "ax_c.set_ylabel(r'$k_{t+1}$', fontsize=12)\n",
    "ax_c.set_title('Capital Stock', fontsize=12)\n",
    "ax_c.legend(frameon=False, fontsize=10)\n",
    "\"\"\"\n",
    "# (3) Lagrange multiplier: μ_t vs k_t\n",
    "ax_c.plot(a[T], mu[T], '.', markersize=0.5, color='k', rasterized=True)\n",
    "ax_c.set_xlabel(r'$\\log(z_t)$', fontsize=12)\n",
    "ax_c.set_ylabel(r'$\\mu_t$', fontsize=12)\n",
    "ax_c.set_title('Lagrange Multiplier', fontsize=12)\n",
    "\n",
    "# (4) Lagrange multiplier: μ_t vs k_t\n",
    "ax_d.plot(k[T], mu[T], '.', markersize=0.5, color='k', rasterized=True)\n",
    "ax_d.set_xlabel(r'$k_t$', fontsize=12)\n",
    "ax_d.set_ylabel(r'$\\mu_t$', fontsize=12)\n",
    "ax_d.set_title('Lagrange Multiplier', fontsize=12)\n",
    "\n",
    "# (5) Time series of i_t over T0\n",
    "ax_e.plot(it[T0], 'k')\n",
    "ax_e.set_xlabel('Time', fontsize=12)\n",
    "ax_e.set_ylabel(r'$i_t$', fontsize=12)\n",
    "ax_e.set_title('Investment (Time Series)', fontsize=12)\n",
    "\n",
    "# (6) Time series of μ_t over T0\n",
    "ax_f.plot(mu[T0], 'k')\n",
    "ax_f.set_xlabel('Time', fontsize=12)\n",
    "ax_f.set_ylabel(r'$\\mu_t$', fontsize=12)\n",
    "ax_f.set_title('Lagrange Multiplier (Time Series)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_folder + \"example_simlation_binding_3x2.pdf\", dpi=300)\n",
    "plt.savefig(output_folder + \"example_simlation_binding_3x2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47db78-3a40-4c70-83a9-245fcd64df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_M = df_results_standard_PEA_M[\"M\"]\n",
    "ref_index_plot = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "axs[0].plot(list_M, df_results_standard_PEA_M[\"DHM_stat\"])\n",
    "axs[0].plot(list_M, df_results_standard_PEA_M[\"DHM_stat\"][ref_index_plot]*(list_M[ref_index_plot]/list_M), linestyle='--', label='1/N decay')\n",
    "axs[0].set_xlabel('DHM stat', fontname='Times', fontsize=12)\n",
    "axs[0].set_title('DHM stat', fontname='Times', fontsize=12)\n",
    "\n",
    "axs[1].plot(list_M, np.abs(df_results_standard_PEA_M[\"C_equivalent\"]))\n",
    "axs[1].plot(list_M, np.abs(df_results_standard_PEA_M[\"C_equivalent\"])[ref_index_plot]*(list_M[ref_index_plot]/list_M), linestyle='--', label='1/N decay')\n",
    "axs[1].set_xlabel('% C equivalent', fontname='Times', fontsize=12)\n",
    "axs[1].set_title('% C equivalent', fontname='Times', fontsize=12)\n",
    "\n",
    "axs[2].plot(df_results_standard_PEA_M[\"M\"], np.abs(df_results_standard_PEA_M[\"MSE\"]))\n",
    "#axs[2].plot(list_M, np.abs(df_results_standard_PEA_M[\"MSE\"])[ref_index_plot]*(list_M[ref_index_plot]/list_M), linestyle='--', label='1/N decay')\n",
    "axs[2].set_xlabel('MSE', fontname='Times', fontsize=12)\n",
    "axs[2].set_title('In-sample MSE', fontname='Times', fontsize=12)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffd994-c69d-4be9-8db4-8d968f201a29",
   "metadata": {},
   "source": [
    "#### II.C.2 bc-MC-PEA\n",
    "\n",
    "Use several innovation draws per state vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5a97f-4022-4435-8ff4-b06c33f26946",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def generate_random_innovations(slong, N, std):\n",
    "    \"\"\"\n",
    "    Generate 1d innovatio N(0, std^2)\n",
    "    \"\"\"\n",
    "    e = np.empty(slong)\n",
    "    for i in range(slong):\n",
    "        e[i] = std * np.random.randn()\n",
    "    return e\n",
    "\n",
    "@njit\n",
    "def generate_random_arrays(slong, N, std):\n",
    "    \"\"\"\n",
    "    Generate 1d innovation N(0, std^2) and random array, where each row is N(0, std^2).\n",
    "    \"\"\"\n",
    "    e = np.empty(slong)\n",
    "    E = np.empty((slong, N))\n",
    "    for i in range(slong):\n",
    "        e[i] = std * np.random.randn()\n",
    "        for j in range(N):\n",
    "            E[i, j] = std * np.random.randn()\n",
    "    return e, E\n",
    "\n",
    "\n",
    "def create_plots(list_N, MSE_N, Time_N, mean_square_ut_N, dhm_stat_N, c_equivalent_N, label = \"N\", ref_index_plot=0):\n",
    "    \"\"\"\n",
    "    Creates two sets of plots:\n",
    "\n",
    "    1. A figure with two subplots:\n",
    "       - Left: MSE vs. N, along with 1/N and 1/sqrt(N) decay lines.\n",
    "       - Right: Elapsed Time vs. N, along with 1*N and 1*sqrt(N) increase lines.\n",
    "\n",
    "    2. A second figure with four subplots (2x2 grid):\n",
    "       - Top-left: Mean (ut)^2 vs. N with a 1/sqrt(N) decay line.\n",
    "       - Top-right: DHM Stats vs. N with a 1/sqrt(N) decay line.\n",
    "       - Bottom-left: % C equivalent vs. N with a 1/sqrt(N) decay line.\n",
    "       - Bottom-right: In sample MSE vs. N with a 1/N decay line.\n",
    "\n",
    "    Parameters:\n",
    "        list_N         : array-like, values of N (Number of Innovation Draws)\n",
    "        MSE_N          : array-like, Mean Squared Error for each N\n",
    "        Time_N         : array-like, elapsed time (seconds) for each N\n",
    "        mean_square_ut_N: array-like, mean (ut)^2 for each N\n",
    "        dhm_stat_N     : array-like, DHM statistic for each N\n",
    "        c_equivalent_N : array-like, % C equivalent for each N\n",
    "        ref_index_plot : int, reference index for plotting the decay/increase lines (default 0)\n",
    "    \"\"\"\n",
    "    list_N = np.array(list_N)  # ensure numpy array for elementwise operations\n",
    "\n",
    "    # -----------------------\n",
    "    # Figure 1: Two subplots side-by-side.\n",
    "    fig1, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Left panel: MSE vs. N.\n",
    "    axs[0].plot(list_N, MSE_N, marker='o', linestyle='-', label='MSE')\n",
    "    axs[0].plot(list_N, MSE_N[ref_index_plot] * (list_N[ref_index_plot] / list_N),\n",
    "                marker='o', linestyle='--', label='1/N decay')\n",
    "    axs[0].plot(list_N, MSE_N[ref_index_plot] * np.sqrt(list_N[ref_index_plot] / list_N),\n",
    "                marker='o', linestyle='--', label='1/sqrt(N) decay')\n",
    "    axs[0].set_xlabel(label)\n",
    "    axs[0].set_ylabel('Mean Squared Error')\n",
    "    axs[0].set_title(f'MSE vs. {label}')\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Right panel: Elapsed Time vs. N.\n",
    "    axs[1].plot(list_N, Time_N, marker='o', linestyle='-', color='orange', label='Elapsed Time (s)')\n",
    "    #axs[1].plot(list_N, Time_N[ref_index_plot] * (list_N / list_N[ref_index_plot]),\n",
    "    #            marker='o', linestyle='--', label='1*N increase')\n",
    "    #axs[1].plot(list_N, Time_N[ref_index_plot] * np.sqrt(list_N / list_N[ref_index_plot]),\n",
    "    #            marker='o', linestyle='--', label='1*sqrt(N) increase')\n",
    "    axs[1].set_xlabel('label')\n",
    "    axs[1].set_ylabel('Elapsed Time (seconds)')\n",
    "    axs[1].set_title(f'Elapsed Time vs. {label}')\n",
    "    axs[1].grid(True)\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -----------------------\n",
    "    # Figure 2: Four subplots in a 2x2 grid.\n",
    "    fig2, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 5))\n",
    "\n",
    "    # Top-left: Mean (ut)^2 vs. N.\n",
    "    ax1.plot(list_N, mean_square_ut_N, marker='o', linestyle='-')\n",
    "    ax1.plot(list_N, mean_square_ut_N[ref_index_plot] * np.power(list_N[ref_index_plot] / list_N, 0.5),\n",
    "             marker='o', linestyle='--', label='1/sqrt(N) decay')\n",
    "    ax1.set_xlabel(label)\n",
    "    ax1.set_ylabel('Mean (ut)^2')\n",
    "    ax1.set_title('Mean (ut)^2')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Top-right: DHM Stats vs. N.\n",
    "    ax2.plot(list_N, dhm_stat_N, marker='o', linestyle='-', color='orange')\n",
    "    ax2.plot(list_N, dhm_stat_N[ref_index_plot] * np.sqrt(list_N[ref_index_plot] / list_N),\n",
    "             marker='o', linestyle='--', label='1/sqrt(N) decay')\n",
    "    ax2.set_xlabel(label)\n",
    "    ax2.set_ylabel('DHM Stats')\n",
    "    ax2.set_title('DHM Stats')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "    # Bottom-left: % C equivalent vs. N.\n",
    "    ax3.plot(list_N, c_equivalent_N, marker='o', linestyle='-', color='orange')\n",
    "    ax3.plot(list_N, c_equivalent_N[ref_index_plot] * np.sqrt(list_N[ref_index_plot] / list_N),\n",
    "             marker='o', linestyle='--', label='1/sqrt(N) decay')\n",
    "    ax3.set_xlabel(label)\n",
    "    ax3.set_ylabel('% C equivalent')\n",
    "    ax3.set_title('% C equivalent')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend()\n",
    "\n",
    "    # Bottom-right: In sample MSE vs. N.\n",
    "    ax4.plot(list_N, MSE_N, marker='o', linestyle='-', label='In sample MSE')\n",
    "    ax4.plot(list_N, MSE_N[ref_index_plot] * (list_N[ref_index_plot] / list_N),\n",
    "             marker='o', linestyle='--', label='1/N decay')\n",
    "    ax4.set_xlabel(label)\n",
    "    ax4.set_ylabel('% In sample MSE')\n",
    "    ax4.set_title('% In sample MSE')\n",
    "    ax4.grid(True)\n",
    "    ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a235eb-33ba-4f4b-8ea1-4b955d8a2c85",
   "metadata": {
    "id": "a8a235eb-33ba-4f4b-8ea1-4b955d8a2c85"
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def clamp(arr, low, high):\n",
    "    \"\"\"\n",
    "    Element-wise clamp of `arr` between `low` and `high`.\n",
    "    Equivalent to np.clip(arr, low, high). np.clip has trouble with jit compilation.\n",
    "    \"\"\"\n",
    "    return np.minimum(np.maximum(arr, low), high)\n",
    "\n",
    "\n",
    "@njit\n",
    "def fill_X_next(Xv, x1, x2, nb_expl_vars, basis):\n",
    "    \"\"\"\n",
    "    In‐place fill of Xv (shape = (nb_expl_vars,)) for a single point (x1,x2),\n",
    "    using monomial basis (basis=1) or Chebyshev basis (basis=2),\n",
    "    with nb_expl_vars in {4,6,10}.\n",
    "    \"\"\"\n",
    "    # 4‐term cross basis\n",
    "    if nb_expl_vars == 4:\n",
    "        Xv[0] = 1.0\n",
    "        Xv[1] = x1\n",
    "        Xv[2] = x2\n",
    "        Xv[3] = x1 * x2\n",
    "        return\n",
    "\n",
    "    if basis == 1:\n",
    "        # —— Monomial —— \n",
    "        if nb_expl_vars == 6:\n",
    "            # [1, x1, x2, x1*x2, x1^2, x2^2]\n",
    "            Xv[0] = 1.0\n",
    "            Xv[1] = x1\n",
    "            Xv[2] = x2\n",
    "            Xv[3] = x1 * x2\n",
    "            Xv[4] = x1 * x1\n",
    "            Xv[5] = x2 * x2\n",
    "            return\n",
    "        else:\n",
    "            # nb_expl_vars == 10\n",
    "            # [1, x1, x2, x1*x2, x1^2, x2^2, x1^3, x1^2*x2, x1*x2^2, x2^3]\n",
    "            Xv[0] = 1.0\n",
    "            Xv[1] = x1\n",
    "            Xv[2] = x2\n",
    "            Xv[3] = x1 * x2\n",
    "            Xv[4] = x1 * x1\n",
    "            Xv[5] = x2 * x2\n",
    "            Xv[6] = x1 * x1 * x1\n",
    "            Xv[7] = x1 * x1 * x2\n",
    "            Xv[8] = x1 * x2 * x2\n",
    "            Xv[9] = x2 * x2 * x2\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        # —— Chebyshev ——\n",
    "        if nb_expl_vars == 6:\n",
    "            # [1, x1, x2, x1*x2, x1^2-1, x2^2-1]\n",
    "            Xv[0] = 1.0\n",
    "            Xv[1] = x1\n",
    "            Xv[2] = x2\n",
    "            Xv[3] = x1 * x2\n",
    "            Xv[4] = x1 * x1 - 1.0\n",
    "            Xv[5] = x2 * x2 - 1.0\n",
    "            return\n",
    "        else:\n",
    "            # nb_expl_vars == 10\n",
    "            # [1, x1, x2, x1*x2, x1^2-1, x2^2-1,\n",
    "            #  4x1^3-3x1, 4x2^3-3x2, (x1^2-1)*x2, x1*(x2^2-1)]\n",
    "            Xv[0] = 1.0\n",
    "            Xv[1] = x1\n",
    "            Xv[2] = x2\n",
    "            Xv[3] = x1 * x2\n",
    "            Xv[4] = x1 * x1 - 1.0\n",
    "            Xv[5] = x2 * x2 - 1.0\n",
    "            Xv[6] = 4.0*x1*x1*x1 - 3.0*x1\n",
    "            Xv[7] = 4.0*x2*x2*x2 - 3.0*x2\n",
    "            Xv[8] = (x1*x1 - 1.0) * x2\n",
    "            Xv[9] = x1 * (x2*x2 - 1.0)\n",
    "            return\n",
    "\n",
    "\n",
    "@njit\n",
    "def simulate_path_N(slong, kss, e, E, b0, beta, gamma, alpha, delta, rho_tfp, N, nb_expl_vars, tol_c, center_dep_var, normalize_dep_var, basis):\n",
    "    \"\"\"\n",
    "    Simulates the model path period by period.\n",
    "\n",
    "    Parameters:\n",
    "        slong   : total number of simulation periods (integer)\n",
    "        kss     : steady state capital (float)\n",
    "        e       : array of nnovations of shape (slong)\n",
    "        E       : array of extra innovations of shape (slong, N)\n",
    "        b0      : coefficient vector (array of length 6)\n",
    "        beta    : discount factor (float)\n",
    "        gamma   : CRRA coefficient (float)\n",
    "        alpha   : production elasticity (float)\n",
    "        delta   : depreciation rate (float)\n",
    "        rho_tfp : AR(1) coefficient for TFP (float)\n",
    "        N       : number of innovations per period (integer)\n",
    "    \"\"\"\n",
    "    # Preallocate arrays\n",
    "    a = np.zeros(slong)\n",
    "    k      = np.zeros(slong + 1)    # capital path (slong+1 because we update k[i+1])\n",
    "    mu     = np.zeros(slong + 1)    # Lagrange multiplier on investment constraint\n",
    "    y      = np.zeros(slong)        # simulated y\n",
    "    production = np.zeros(slong)    # production\n",
    "    inv = np.zeros(slong)           # investment\n",
    "    cash     = np.zeros(slong)      # cash in hand\n",
    "    c = np.zeros(slong)             # consumption\n",
    "    X      = np.zeros((slong, nb_expl_vars))   # regressor matrix (6 variables)\n",
    "    X_next = np.zeros(nb_expl_vars) # regressor, next period\n",
    "    y_temp = np.zeros(N)            # temporary array for innovations\n",
    "\n",
    "    # To ensure consumption is a least tol_c\n",
    "    E_max = tol_c**(-gamma)\n",
    "    \n",
    "    # Initialize state.\n",
    "    k[0] = kss\n",
    "    a[0] = 0.0\n",
    "    for i in range(1, slong):\n",
    "        a[i] = rho_tfp * a[i-1] + e[i]\n",
    "\n",
    "    for i in range(slong):\n",
    "        # Build regressor vector for current period i: [1, log(k[i]), a[i], log(k[i])^2, a[i]^2, log(k[i])*a[i]]\n",
    "        x1 = np.log(k[i])\n",
    "        x2 = a[i]\n",
    "\n",
    "        \"\"\"\n",
    "        if nb_expl_vars == 4:\n",
    "            X[i, :] = np.array([1, x1, x2, x1 * x2])\n",
    "        else:\n",
    "            if basis == 1:\n",
    "                X[i, :] = np.array([1, x1, x2, x1 * x2, x1**2, x2**2])\n",
    "            else:\n",
    "                X[i, :] = np.array([1, x1, x2, x1 * x2, (x1**2 - 1), (x2**2-1)])\n",
    "        \"\"\"\n",
    "        fill_X_row(X, i, x1, x2, nb_expl_vars, basis)\n",
    "        \n",
    "        production[i] = np.exp(a[i]) * k[i] ** alpha \n",
    "        cash[i] = production[i] + (1 - delta) * k[i]\n",
    "\n",
    "        # Consumption, if current constraint on investment does not bind:\n",
    "        E_t_tilde = np.exp(np.dot(X[i, :], b0))\n",
    "        # E_t_tilde = clamp(np.exp(np.dot(X[i, :], b0)), production[i]**(-gamma), E_max) \n",
    "        c[i] = E_t_tilde ** (-1 / gamma)\n",
    "\n",
    "        # Update guess, after calculating investment\n",
    "        inv[i] = production[i] - c[i]\n",
    "        if inv[i] > 0:\n",
    "            k[i+1] = cash[i] - c[i]\n",
    "        else:\n",
    "            k[i+1] = (1 - delta) * k[i]\n",
    "            c[i] = production[i]\n",
    "            mu[i] = c[i]**( - gamma ) - E_t_tilde\n",
    "\n",
    "        # Move to next period\n",
    "        ## precalculate too avoid repeated calculations\n",
    "        term1 = alpha * (k[i+1]**(alpha - 1)) \n",
    "        term2 = k[i+1] ** alpha \n",
    "        a_tilde = rho_tfp * a[i]\n",
    "        \n",
    "        x1_next = np.log(k[i+1])\n",
    "        \n",
    "        ## Start building regressor next period\n",
    "        \"\"\"\n",
    "        if nb_expl_vars == 4:\n",
    "            X_next = np.array([1, x1_next, 0.0, 0.0])\n",
    "        else:\n",
    "            if basis == 1:\n",
    "                X_next = np.array([1, x1_next, 0.0, 0.0, x1_next**2, 0.0])\n",
    "            else:\n",
    "                X_next = np.array([1, x1_next, 0.0, 0.0, (x1_next**2 - 1), 0.0])\n",
    "        \"\"\"\n",
    "\n",
    "        # For each of the N innovations compute a simulated realization for y\n",
    "        for j in range(N):\n",
    "            # Next period's TFP shock\n",
    "            a_next = a_tilde + E[i, j]\n",
    "\n",
    "            # production next period:\n",
    "            production_next = np.exp(a_next) * term2\n",
    "            \n",
    "            ## Without repeated calculations\n",
    "            # Build regressor for next period using k[i+1] and a_next\n",
    "            x2_next = a_next\n",
    "\n",
    "            \"\"\"\n",
    "            if nb_expl_vars == 4:\n",
    "                X_next[2] = x2_next\n",
    "                X_next[3] = x1_next * x2_next\n",
    "            else:\n",
    "                if basis == 1:\n",
    "                    X_next[2] = x2_next\n",
    "                    X_next[3] = x1_next * x2_next\n",
    "                    X_next[5] = x2_next**2\n",
    "                else:\n",
    "                    X_next[2] = x2_next\n",
    "                    X_next[3] = x1_next * x2_next\n",
    "                    X_next[5] = (x2_next**2 - 1)\n",
    "            \"\"\"\n",
    "            fill_X_next(X_next, x1_next, x2_next, nb_expl_vars, basis)\n",
    "\n",
    "            #c_next = np.maximum(tol_c, css*(1 + np.dot(X_next, b0))**(-1/gamma))\n",
    "            E_next_tilde = np.exp(np.dot(X_next, b0))\n",
    "            #E_next_tilde = clamp(np.dot(X_next, b0), production_next**(-gamma), E_max) \n",
    "            c_next = E_next_tilde ** (-1 / gamma)\n",
    "            \n",
    "            # Update guess, after calculating investment\n",
    "            inv_next = production_next - c_next\n",
    "            if inv_next > 0:\n",
    "                # non-binding\n",
    "                mu_next = 0\n",
    "            else:\n",
    "                # binding\n",
    "                c_next = production_next\n",
    "                mu_next = c_next**( - gamma ) - E_next_tilde\n",
    "                \n",
    "            ## g2(s,e)\n",
    "            y_temp[j] =  ( c_next**(-gamma) ) * (np.exp(a_next) * term1 + 1.0 - delta ) + mu_next * (1.0 - delta) \n",
    "\n",
    "        # Average the N innovations to form the simulated y for period i\n",
    "        s = 0.0\n",
    "        for j in range(N):\n",
    "            s += y_temp[j]\n",
    "\n",
    "        # Sample average to proxy an expectation:\n",
    "        y[i] = np.log( beta * (s / N) ) \n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "@njit\n",
    "def simulate_path_N_inplace(\n",
    "    M: int,\n",
    "    init: int,\n",
    "    kss: float,\n",
    "    e: np.ndarray,\n",
    "    E: np.ndarray,\n",
    "    b0: np.ndarray,\n",
    "    beta: float,\n",
    "    gamma: float,\n",
    "    alpha: float,\n",
    "    delta: float,\n",
    "    rho_tfp: float,\n",
    "    N: int,\n",
    "    nb_expl_vars: int,\n",
    "    tol_c: float,\n",
    "    center_dep_var: bool,\n",
    "    normalize_dep_var: bool,\n",
    "    basis: int,\n",
    "    a: np.ndarray,\n",
    "    k: np.ndarray,\n",
    "    mu: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    production: np.ndarray,\n",
    "    inv: np.ndarray,\n",
    "    cash: np.ndarray,\n",
    "    c: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    X_next: np.ndarray,\n",
    "    y_temp: np.ndarray\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Simulates one path of the neoclassical growth model using a Parameterized Expectations Algorithm (PEA)\n",
    "    with in-place mutation of pre-allocated arrays. JIT-compiled with numba for maximum performance.\n",
    "\n",
    "    All outputs are written directly into the provided arrays; no value is returned.\n",
    "    \"\"\"\n",
    "    slong = M + init\n",
    "\n",
    "    # To ensure consumption is a least tol_c\n",
    "    E_max = tol_c**(-gamma)\n",
    "    \n",
    "    # Set value for constant vector\n",
    "    X[:, 0] = 1.0\n",
    "\n",
    "    # Unpack coefficients for inlined dot-products\n",
    "    \"\"\"\n",
    "    b0_0 = b0[0]; b0_1 = b0[1]; b0_2 = b0[2]; b0_3 = b0[3]\n",
    "    if nb_expl_vars > 4:\n",
    "        b0_4 = b0[4]; b0_5 = b0[5]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize state\n",
    "    k[0] = kss\n",
    "    a[0] = 0.0\n",
    "    for i in range(1, slong):\n",
    "        a[i] = rho_tfp * a[i-1] + e[i]\n",
    "\n",
    "    for i in range(0, slong):\n",
    "        # Compute regressors x1, x2\n",
    "        x1 = np.log(k[i])\n",
    "        x2 = a[i]\n",
    "\n",
    "        # Fill in X[i] for OLS regression y = X*b\n",
    "        \"\"\"\n",
    "        if nb_expl_vars == 4:\n",
    "            X[i, 1] = x1; X[i, 2] = x2; X[i, 3] = x1 * x2\n",
    "        else:\n",
    "            if basis == 1:\n",
    "                X[i, 1] = x1; X[i, 2] = x2; X[i, 3] = x1 * x2; X[i, 4] = x1**2; X[i, 5] = x2**2\n",
    "            else:\n",
    "                X[i, 1] = x1; X[i, 2] = x2; X[i, 3] = x1 * x2; X[i, 4] = x1**2 - 1.0; X[i, 5] = x2**2 - 1.0\n",
    "        \"\"\"\n",
    "        fill_X_row(X, i, x1, x2, nb_expl_vars, basis)\n",
    "        \n",
    "        # Cash-in-hand and consumption decision        \n",
    "        production[i] = np.exp(a[i]) * k[i] ** alpha \n",
    "        cash[i] = production[i] + (1 - delta) * k[i]\n",
    "\n",
    "        # Consumption, if current constraint on investment does not bind:\n",
    "        ## Dot product\n",
    "        \"\"\"\n",
    "        if nb_expl_vars == 4:\n",
    "            scalar = b0_0 + b0_1 * x1 + b0_2 * x2 + b0_3 * (x1 * x2)\n",
    "        else:\n",
    "            if basis == 1:\n",
    "                scalar = (b0_0 + b0_1 * x1 + b0_2 * x2 + b0_3 * (x1 * x2)\n",
    "                          + b0_4 * (x1**2) + b0_5 * (x2**2))\n",
    "            else:\n",
    "                scalar = (b0_0 + b0_1 * x1 + b0_2 * x2 + b0_3 * (x1 * x2)\n",
    "                          + b0_4 * (x1**2 - 1.0) + b0_5 * (x2**2 - 1.0))\n",
    "        \"\"\"\n",
    "        scalar = np.dot(X[i, :], b0)\n",
    "        \n",
    "        #E_t_tilde = clamp(np.exp(scalar), production[i]**(-gamma), E_max)\n",
    "        E_t_tilde = np.exp(scalar)\n",
    "        c[i] = E_t_tilde ** (-1 / gamma)\n",
    "\n",
    "        # Update guess, after calculating investment\n",
    "        inv[i] = production[i] - c[i]\n",
    "        if inv[i] > 0:\n",
    "            k[i+1] = cash[i] - c[i]\n",
    "            mu[i] = 0.0\n",
    "        else:\n",
    "            k[i+1] = (1 - delta) * k[i]\n",
    "            c[i] = production[i]\n",
    "            mu[i] = c[i]**( - gamma ) - E_t_tilde\n",
    "            \n",
    "        # Only do MC expectation for i >= init. No need for burnin phase\n",
    "        if i >= init:\n",
    "            # Prepare next-period terms (precalculation of terms that do not depend on j)\n",
    "            term1 = alpha * k[i+1]**(alpha - 1.0)\n",
    "            term2 = k[i+1] ** alpha \n",
    "            a_tilde = rho_tfp * a[i]\n",
    "        \n",
    "            x1_next = np.log(k[i+1])\n",
    "    \n",
    "            # Monte Carlo expectation\n",
    "            for j in range(N):\n",
    "                a_next = a_tilde + E[i, j]\n",
    "                # production next period:\n",
    "                production_next = np.exp(a_next) * term2\n",
    "            \n",
    "                x2_next = a_next\n",
    "\n",
    "                \"\"\"\n",
    "                if nb_expl_vars == 4:\n",
    "                    scalar_next = (b0_0 + b0_1 * x1_next + b0_2 * x2_next\n",
    "                                   + b0_3 * (x1_next * x2_next))\n",
    "                else:\n",
    "                    if basis == 1:\n",
    "                        scalar_next = (b0_0 + b0_1 * x1_next + b0_2 * x2_next\n",
    "                                       + b0_3 * (x1_next * x2_next)\n",
    "                                       + b0_4 * (x1_next**2) + b0_5 * (x2_next**2))\n",
    "                    else:\n",
    "                        scalar_next = (b0_0 + b0_1 * x1_next + b0_2 * x2_next\n",
    "                                       + b0_3 * (x1_next * x2_next)\n",
    "                                       + b0_4 * (x1_next**2 - 1.0)\n",
    "                                       + b0_5 * (x2_next**2 - 1.0))\n",
    "                \"\"\"\n",
    "                fill_X_next(X_next, x1_next, x2_next, nb_expl_vars, basis)\n",
    "                scalar_next = np.dot(X_next, b0)\n",
    "                \n",
    "                # Consumption next period, assuming constraint does not bind:\n",
    "                #E_next_tilde = clamp(np.exp(scalar_next), production_next ** (-gamma), E_max)\n",
    "                E_next_tilde = np.exp(scalar_next)\n",
    "                c_next = E_next_tilde ** (-1 / gamma)\n",
    "            \n",
    "                # Update guess, after calculating investment\n",
    "                inv_next = production_next - c_next\n",
    "                if inv_next > 0:\n",
    "                    # non-binding\n",
    "                    mu_next = 0\n",
    "                else:\n",
    "                    # binding\n",
    "                    c_next = production_next\n",
    "                    mu_next = c_next**( - gamma ) - E_next_tilde\n",
    "            \n",
    "                ## g2(s,e)\n",
    "                y_temp[j] =  ( c_next**( -gamma ) ) * ( np.exp(a_next) * term1 + 1.0 - delta ) + mu_next * (1.0 - delta) \n",
    "    \n",
    "            # Final aggregation\n",
    "            s = 0.0\n",
    "            for j in range(N):\n",
    "                s += y_temp[j]\n",
    "            \n",
    "            y[i] = np.log( beta * (s / N) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575aacb-d861-419b-867a-fabe8ad2be84",
   "metadata": {
    "id": "b575aacb-d861-419b-867a-fabe8ad2be84"
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def evaluate_IE_and_EEE_Gauss_path_inplace(\n",
    "    slong: int,\n",
    "    kss: float,\n",
    "    e: np.ndarray,\n",
    "    b0: np.ndarray,\n",
    "    beta: float,\n",
    "    gamma: float,\n",
    "    alpha: float,\n",
    "    delta: float,\n",
    "    rho_tfp: float,\n",
    "    number_nodes: int,\n",
    "    quadrature_nodes: np.ndarray,\n",
    "    quadrature_weights: np.ndarray,\n",
    "    nb_expl_vars: int,\n",
    "    tol_c: float,\n",
    "    center_dep_var: bool,\n",
    "    normalize_dep_var: bool,\n",
    "    basis: int,\n",
    "    # Preallocated arrays for in-place mutation:\n",
    "    a: np.ndarray,            # shape (slong,)\n",
    "    k: np.ndarray,            # shape (slong+1,)\n",
    "    mu: np.ndarray,           # shape (slong+1,)\n",
    "    production: np.ndarray,   # shape (slong,)\n",
    "    inv: np.ndarray,          # shape (slong,)\n",
    "    IE: np.ndarray,           # shape (slong,)\n",
    "    EEE: np.ndarray,          # shape (slong,)\n",
    "    cash: np.ndarray,         # shape (slong,)\n",
    "    c: np.ndarray,            # shape (slong,)\n",
    "    X: np.ndarray,            # shape (slong, nb_expl_vars)\n",
    "    X_next: np.ndarray,       # shape (nb_expl_vars,)\n",
    "    linear_model: np.ndarray, # shape (slong,)\n",
    "    y_temp1: np.ndarray,      # shape (number_nodes,)\n",
    ") -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    In-place computation of MSIE (IE) and Euler equation errors (EEE)\n",
    "    along a single simulated path using Gauss–Hermite quadrature.\n",
    "\n",
    "    All output arrays (a, k, IE, EEE, cash, c, X, X_next, linear_model,\n",
    "    y_temp1, y_temp2) must be pre-allocated to the correct shape.\n",
    "    \"\"\"\n",
    "    # Clear values\n",
    "    a[:] = 0.0\n",
    "    k[:] = 0.0\n",
    "    mu[:] = 0.0\n",
    "    production[:] = 0.0\n",
    "    inv[:] = 0.0\n",
    "    IE[:] = 0.0\n",
    "    EEE[:] = 0.0\n",
    "    cash[:] = 0.0\n",
    "    c[:] = 0.0\n",
    "    X[:,:] = 0.0\n",
    "    X_next[:] = 0.0\n",
    "    linear_model[:] = 0.0\n",
    "    y_temp1[:] = 0.0\n",
    "\n",
    "    # To ensure consumption is a least tol_c\n",
    "    E_max = tol_c**(-gamma)\n",
    "\n",
    "    # Set initial state\n",
    "    k[0] = kss\n",
    "    a[0] = 0.0\n",
    "\n",
    "    # AR(1) TFP path\n",
    "    for i in range(1, slong):\n",
    "        a[i] = rho_tfp * a[i - 1] + e[i]\n",
    "\n",
    "    # Unpack b0 for inlined dot-products\n",
    "    \"\"\"\n",
    "    b0_0 = b0[0]; b0_1 = b0[1]; b0_2 = b0[2]; b0_3 = b0[3]\n",
    "    if nb_expl_vars > 4:\n",
    "        b0_4 = b0[4]; b0_5 = b0[5]\n",
    "    \"\"\"\n",
    "\n",
    "    # Main loop\n",
    "    for i in range(slong):\n",
    "        # 1) build current regressors x1,x2\n",
    "        x1 = np.log(k[i])\n",
    "        x2 = a[i]\n",
    "\n",
    "        # 2) fill X[i]\n",
    "        \"\"\"\n",
    "        X[i, 0] = 1.0\n",
    "        X[i, 1] = x1\n",
    "        X[i, 2] = x2\n",
    "        X[i, 3] = x1 * x2\n",
    "        if nb_expl_vars > 4:\n",
    "            if basis == 1:\n",
    "                X[i, 4] = x1 * x1\n",
    "                X[i, 5] = x2 * x2\n",
    "            else:\n",
    "                X[i, 4] = x1 * x1 - 1.0\n",
    "                X[i, 5] = x2 * x2 - 1.0\n",
    "        \"\"\"\n",
    "        fill_X_row(X, i, x1, x2, nb_expl_vars, basis)\n",
    "\n",
    "        # 3) cash, linear prediction, consumption, and k forward\n",
    "        production[i] = np.exp(a[i]) * k[i] ** alpha \n",
    "        cash[i] = production[i] + (1 - delta) * k[i]\n",
    "               \n",
    "        # inline dot(X[i], b0)\n",
    "        \"\"\"\n",
    "        if nb_expl_vars == 4:\n",
    "            scalar = b0_0 + b0_1*x1 + b0_2*x2 + b0_3*(x1*x2)\n",
    "        else:\n",
    "            if basis == 1:\n",
    "                scalar = (b0_0 + b0_1*x1 + b0_2*x2 + b0_3*(x1*x2)\n",
    "                          + b0_4*(x1*x1) + b0_5*(x2*x2))\n",
    "            else:\n",
    "                scalar = (b0_0 + b0_1*x1 + b0_2*x2 + b0_3*(x1*x2)\n",
    "                          + b0_4*(x1*x1 - 1.0) + b0_5*(x2*x2 - 1.0))\n",
    "        \"\"\"\n",
    "        scalar = np.dot(X[i, :], b0)\n",
    "        \n",
    "        linear_model[i] = scalar\n",
    "        #E_t_tilde = clamp(np.exp(linear_model[i]), production[i]**(-gamma), E_max) \n",
    "        E_t_tilde = np.exp(linear_model[i])\n",
    "        c[i] = E_t_tilde ** (-1 / gamma)\n",
    "\n",
    "        # Update guess, after calculating investment\n",
    "        inv[i] = production[i] - c[i]\n",
    "        if inv[i] > 0:\n",
    "            k[i+1] = cash[i] - c[i]\n",
    "            mu[i] = 0.0\n",
    "        else:\n",
    "            k[i+1] = (1 - delta) * k[i]\n",
    "            c[i] = production[i]\n",
    "            mu[i] = c[i]**( - gamma ) - E_t_tilde\n",
    "\n",
    "        # Precompute next‐period quantities\n",
    "        x1_next = np.log(k[i+1])\n",
    "        \n",
    "        term1 = alpha * (k[i+1] ** (alpha - 1.0))\n",
    "        term2 = k[i+1] ** alpha \n",
    "        a_tilde = rho_tfp * a[i]\n",
    "        \n",
    "        # 4) Quadrature loop\n",
    "        for j in range(number_nodes):\n",
    "            a_next = a_tilde + quadrature_nodes[j]\n",
    "\n",
    "            # production next period:\n",
    "            production_next = np.exp(a_next) * term2\n",
    "            \n",
    "            x2_next = a_next\n",
    "\n",
    "            # inline dot(X_next, b0)\n",
    "            \"\"\"\n",
    "            if nb_expl_vars == 4:\n",
    "                scalar_next = (b0_0 + b0_1*x1_next + b0_2*x2_next\n",
    "                               + b0_3*(x1_next*x2_next))\n",
    "            else:\n",
    "                if basis == 1:\n",
    "                    scalar_next = (b0_0 + b0_1*x1_next + b0_2*x2_next\n",
    "                                   + b0_3*(x1_next*x2_next)\n",
    "                                   + b0_4*(x1_next*x1_next)\n",
    "                                   + b0_5*(x2_next*x2_next))\n",
    "                else:\n",
    "                    scalar_next = (b0_0 + b0_1*x1_next + b0_2*x2_next\n",
    "                                   + b0_3*(x1_next*x2_next)\n",
    "                                   + b0_4*(x1_next*x1_next - 1.0)\n",
    "                                   + b0_5*(x2_next*x2_next - 1.0))\n",
    "            \"\"\"\n",
    "            \n",
    "            # Consumption next period, assuming constraint does not bind:\n",
    "            fill_X_next(X_next, x1_next, x2_next, nb_expl_vars, basis)\n",
    "            scalar_next = np.dot(X_next, b0)\n",
    "            \n",
    "            E_next_tilde = np.exp(scalar_next)\n",
    "            c_next = E_next_tilde ** (-1 / gamma)\n",
    "        \n",
    "            # Update guess, after calculating investment\n",
    "            inv_next = production_next - c_next\n",
    "            if inv_next > 0:\n",
    "                # non-binding\n",
    "                mu_next = 0\n",
    "            else:\n",
    "                # binding\n",
    "                c_next = production_next\n",
    "                mu_next = c_next**( - gamma ) - E_next_tilde\n",
    "\n",
    "            # Monte-Carlo expectation terms:\n",
    "            ## RHS of Euler equation   \n",
    "            y_temp1[j] = beta * ( ( c_next ** ( - gamma ) ) * ( np.exp(a_next) * term1 + 1.0 - delta ) + mu_next * (1.0 - delta) )\n",
    "\n",
    "        # 5) Weighted averages & fill IE, EEE\n",
    "        s1 = 0.0\n",
    "        for j in range(number_nodes):\n",
    "            s1 += quadrature_weights[j] * y_temp1[j]\n",
    "            \n",
    "        #Integration error: log(E_t) - x' beta. E_t calculated using Gaussian intergration.\n",
    "        IE[i]  = np.log(s1) - linear_model[i] \n",
    "        #Euler equation error: 1 - (1/c_t)*(E_t()^{-1/gamma})\n",
    "        EEE[i] = 1.0 - (1.0 / c[i]) * ( ( s1  + mu[i] ) **(-1.0 / gamma)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed647c08-66e3-4203-bb17-079d68f4919e",
   "metadata": {
    "id": "ed647c08-66e3-4203-bb17-079d68f4919e"
   },
   "source": [
    "Run for several choices of $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30c53f-b280-466d-9351-28a1bd9629b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae30c53f-b280-466d-9351-28a1bd9629b7",
    "outputId": "157341a3-5720-4b72-e626-e83599907ab0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --------------------------------------------------------------------------\n",
    "# Main code (outside numba) to run the PEA iterations.\n",
    "# --------------------------------------------------------------------------\n",
    "list_N = [1, 2, 5, 10, 100, 200, 500, 1000]\n",
    "MSE_N = np.zeros(len(list_N)) #In-sample\n",
    "MSIE_N = np.zeros(len(list_N)) #Mean square integration error, out-sample\n",
    "A_EEE_N = np.zeros(len(list_N)) #Average absolute value of Euler equation error, out-sample\n",
    "Time_N = np.zeros(len(list_N))\n",
    "\n",
    "nb_tot_reps = 5\n",
    "M = 250\n",
    "init = 100\n",
    "slong = init + M\n",
    "\n",
    "tol = 1e-8\n",
    "gam = 1.0  # smoothing parameter\n",
    "max_iter = 50 # max number of iterations\n",
    "redraw_shocks_every = 1000 #redraw new realizations of innovations (new state and innovation vectors)\n",
    "\n",
    "# Innovations for the out-sample test\n",
    "slong_test = 100000\n",
    "init_test = 1000\n",
    "e_test = params.std_tfp * np.random.randn(slong_test) #New shocks\n",
    "\n",
    "# Preallocate arrays for test\n",
    "a_test            = np.zeros(slong_test)\n",
    "k_test            = np.zeros(slong_test+1)\n",
    "mu_test           = np.zeros(slong_test+1)\n",
    "production_test   = np.zeros(slong_test)\n",
    "inv_test          = np.zeros(slong_test)\n",
    "IE           = np.zeros(slong_test)\n",
    "EEE          = np.zeros(slong_test)\n",
    "cash_test         = np.zeros(slong_test)\n",
    "c_test            = np.zeros(slong_test)\n",
    "X_test            = np.zeros((slong_test, params.nb_expl_vars))\n",
    "X_next_test       = np.zeros(params.nb_expl_vars)\n",
    "linear_model_test = np.zeros(slong_test)\n",
    "y_temp1_test      = np.zeros(len(params.nodes_flat))\n",
    "#y_temp2_test      = np.zeros(len(params.nodes_flat))\n",
    "\n",
    "results = []\n",
    "np.random.seed(1)\n",
    "#for N in range(1, max_N+1):\n",
    "for (index_N, N) in enumerate(list_N):\n",
    "    print(\"Running simulation with N =\", N)\n",
    "    # repeat several times\n",
    "    for nb_rep in range(nb_tot_reps):\n",
    "        b0_current = coeff_array_0.copy()  # initial guess (shape (6,))\n",
    "    \n",
    "        # innovation for state vector (not used directly in simulation here\n",
    "        # for M large, no need to redraw many times.\n",
    "        e = params.std_tfp * np.random.randn(slong)\n",
    "        # extra draws for each state: shape (slong, N)\n",
    "        E = params.std_tfp * np.random.randn(slong, N)\n",
    "    \n",
    "        # Preallocate arrays\n",
    "        a = np.zeros(slong)\n",
    "        k      = np.zeros(slong + 1)    # capital path (slong+1 because we update k[i+1])\n",
    "        mu     = np.zeros(slong + 1)    # Lagrange multiplier on investment constraint\n",
    "        y_out      = np.zeros(slong)    # simulated y\n",
    "        production = np.zeros(slong)    # production\n",
    "        inv = np.zeros(slong)           # investment\n",
    "        cash     = np.zeros(slong)      # cash in hand\n",
    "        c = np.zeros(slong)             # consumption\n",
    "        X_data      = np.zeros((slong, params.nb_expl_vars))   # regressor matrix (6 variables)\n",
    "        X_next = np.zeros(params.nb_expl_vars) # regressor, next period\n",
    "        y_temp = np.zeros(N)            # temporary array for innovations\n",
    "    \n",
    "    \n",
    "        # Warmup (compilation) first go\n",
    "        ## Without preallocations\n",
    "        #X_data, y_out = simulate_path_N(slong, params.kss, e, E, b0_current, params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N, params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis)\n",
    "        ## With preallocations\n",
    "        simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        iter_num = 1\n",
    "        crit = 1.0\n",
    "        # Run a fixed number of iterations (or use while crit > tol)\n",
    "        while iter_num < max_iter:\n",
    "            if iter_num % redraw_shocks_every == 0:\n",
    "                e[:], E[:,:] = generate_random_arrays(slong, N, params.std_tfp)\n",
    "    \n",
    "            # Call the numba-compiled simulation to get regression data.\n",
    "            simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                            params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                            params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                            a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "    \n",
    "            \n",
    "            #X_data, y_out = simulate_path_N(slong, params.kss, e, E, b0_current, params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N, params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis)\n",
    "            \n",
    "            # Remove burnin and last period\n",
    "            X_reg = X_data[init:-1, :]\n",
    "            y_reg = y_out[init:-1]\n",
    "            # OLS\n",
    "            bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)\n",
    "\n",
    "            if params.regression_two_steps == True:\n",
    "                #print(f\"Step 1 coef: {bt}\")\n",
    "                # Square root of weights, when using log model\n",
    "                sqrt_w = np.exp(X_reg @ bt)\n",
    "                # Pre-multiply and then regress again\n",
    "                X_wls = X_reg * sqrt_w[:, None]\n",
    "                y_wls = y_reg * sqrt_w\n",
    "                bt, _, _, _ = np.linalg.lstsq(X_wls, y_wls, rcond=None)\n",
    "            \n",
    "            # Parameter update\n",
    "            b_new = gam * bt + (1 - gam) * b0_current\n",
    "            crit = np.max(np.abs(b_new - b0_current))\n",
    "            b0_current = b_new.copy()\n",
    "            if (iter_num % 10 == 0):\n",
    "                print(\"Iteration:\", iter_num, \"Conv. crit.:\", crit)\n",
    "            iter_num += 1\n",
    "    \n",
    "        end_time = time.perf_counter()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"Elapsed time for N =\", N, \":\", elapsed, \"seconds\")\n",
    "        # Compute residuals and In-sample MSE.\n",
    "        Res = y_reg - np.dot(X_reg, b0_current)\n",
    "        MSE = np.mean(Res ** 2)\n",
    "        MSE_N[index_N] = MSE\n",
    "        # Alternative measure of accuracy\n",
    "        mean_abs_ut, mean_square_ut, std_ut, dhm_stat, c_equivalent = dhm_accuracy_test(params, b0_current, e_test)\n",
    "    \n",
    "        # Mean square integration error and EEE\n",
    "        evaluate_IE_and_EEE_Gauss_path_inplace(slong_test, params.kss, \n",
    "                                             e_test, b0_current, params.beta, params.gamma, params.alpha,\n",
    "                                             params.delta, params.rho_tfp, len(params.nodes_flat),\n",
    "                                             params.nodes_flat, params.weights, params.nb_expl_vars,\n",
    "                                             params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                             a_test, k_test, mu_test, production_test, inv_test,\n",
    "                                             IE, EEE, cash_test, c_test, X_test, X_next_test, linear_model_test,\n",
    "                                             y_temp1_test)\n",
    "    \n",
    "    \n",
    "        MSIE_N[index_N] = np.mean(IE[init_test:-1]**2)\n",
    "        A_EEE_N[index_N] = np.mean(np.abs(EEE[init_test:-1]))\n",
    "    \n",
    "        Time_N[index_N] = elapsed\n",
    "        print(\"Final iteration N:\", N, \"Iterations:\", iter_num, \"OLS MSE:\", MSE, \"MISE:\", MSIE_N[index_N], \"Average EEE:\", A_EEE_N[index_N])\n",
    "        print(\"Final b0:\", b0_current)\n",
    "    \n",
    "        # Store the results in a dictionary\n",
    "        results.append({\n",
    "            \"repetition\": nb_rep,\n",
    "            \"k\": params.nb_expl_vars,\n",
    "            \"M\": M,\n",
    "            \"N\": N,\n",
    "            \"Time\": elapsed,\n",
    "            \"MSE\": MSE,\n",
    "            \"MSIE\": MSIE_N[index_N],\n",
    "            \"A_EEE\": A_EEE_N[index_N],\n",
    "            \"Mean_abs_u\": mean_abs_ut, \n",
    "            \"mean_square_ut\": mean_square_ut, \n",
    "            \"std_ut\": std_ut, \n",
    "            \"dhm_stat\": dhm_stat, \n",
    "            \"c_equivalent\": c_equivalent\n",
    "            })\n",
    "\n",
    "\n",
    "# Create a Pandas DataFrame from the results\n",
    "df_results_N = pd.DataFrame(results)\n",
    "df_results_N.to_csv(output_folder + \"df_results_N.csv\")\n",
    "print(df_results_N.head())\n",
    "\n",
    "# Create average df, averaging over repetitions\n",
    "df_results_N[\"M_init\"]    = df_results_N[\"M\"] + init #add burnin\n",
    "df_results_N[\"log_N\"]    = np.log(df_results_N[\"N\"])\n",
    "df_results_N[\"log_M\"]    = np.log(df_results_N[\"M\"])\n",
    "df_results_N[\"log_MN\"]   = np.log(df_results_N[\"M\"] * df_results_N[\"N\"])\n",
    "df_results_N[\"MN_label\"] = df_results_N[\"M\"].astype(\"str\") + \"-\" + df_results_N[\"N\"].astype(\"str\")\n",
    "\n",
    "# Remove outliers (non-convergence)\n",
    "#df_results_N = df_results_N[df_results_N[\"MSIE\"] < 1.0]\n",
    "\n",
    "df_results_average_N = df_results_N.groupby(\"MN_label\").mean().reset_index()\n",
    "df_results_average_N.sort_values(\"N\", inplace=True)\n",
    "df_results_average_N.to_csv(output_folder + \"df_results_average_N.csv\")\n",
    "print(df_results_average_N.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506f02e-d346-4db3-982d-fa9154955881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_plots(df_results_average_N[\"N\"].values, df_results_average_N[\"MSE\"].values, df_results_average_N[\"Time\"].values, df_results_average_N[\"mean_square_ut\"].values, df_results_average_N[\"dhm_stat\"].values, np.abs(df_results_average_N[\"c_equivalent\"]).values, ref_index_plot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57004c7-b8d7-4637-a57a-06dd59dc6c5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "c57004c7-b8d7-4637-a57a-06dd59dc6c5c",
    "outputId": "ebd8be87-332e-4a23-b2f6-20baacafbfcc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_results_average_N[\"N\"], np.sqrt(df_results_average_N[\"MSIE\"]), label=\"data\")\n",
    "plt.plot(df_results_average_N[\"N\"], np.sqrt(df_results_average_N[\"MSIE\"]))\n",
    "plt.plot(df_results_average_N[\"N\"], np.sqrt(df_results_average_N[\"MSIE\"].values[0] * (df_results_average_N[\"N\"].values[0]/df_results_average_N[\"N\"]) ), label=\"Square root decay\")\n",
    "plt.title(\"Square root mean square integration error\")\n",
    "plt.legend()\n",
    "plt.savefig(output_folder + \"MSIE_N.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df_results_average_N[\"N\"], np.sqrt(df_results_average_N[\"A_EEE\"]), label=\"data\")\n",
    "plt.plot(df_results_average_N[\"N\"], np.sqrt(df_results_average_N[\"A_EEE\"]))\n",
    "plt.plot(df_results_average_N[\"N\"], np.sqrt(df_results_average_N[\"A_EEE\"].values[0] * (df_results_average_N[\"N\"].values[0]/df_results_average_N[\"N\"]) ), label=\"Square root decay\")\n",
    "\n",
    "plt.title(\"Average Euler equation error\")\n",
    "plt.savefig(output_folder + \"A_EEE_N.pdf\", dpi=300)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0244ba5-3598-45f1-bc7f-74207d7576cb",
   "metadata": {
    "id": "f0244ba5-3598-45f1-bc7f-74207d7576cb"
   },
   "source": [
    "several choices of $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b922dc2-55cf-4de1-86fc-f5d7f387c46a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b922dc2-55cf-4de1-86fc-f5d7f387c46a",
    "outputId": "f772b439-3d42-4c90-9e80-c6924879be9c"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Main code (outside numba) to run the PEA iterations.\n",
    "# --------------------------------------------------------------------------\n",
    "list_M = [200, 500, 1000, 5000, 10000, 20000]\n",
    "MSE_M = np.zeros(len(list_M)) #In-sample\n",
    "MSIE_M = np.zeros(len(list_M)) #Mean square integration error, out-sample\n",
    "A_EEE_M = np.zeros(len(list_M)) #Average absolute value of Euler equation error, out-sample\n",
    "Time_M = np.zeros(len(list_M))\n",
    "\n",
    "# Number innovation draws\n",
    "N = 2 #10 #1\n",
    "init = 100 #burnin\n",
    "\n",
    "tol = 1e-8\n",
    "gam = 1.0  # smoothing parameter\n",
    "max_iter = 50 # max number of iterations\n",
    "redraw_shocks_every = 1000 #redraw new realizations of innovations (new state and innovation vectors)\n",
    "\n",
    "# Innovations for the out-sample test\n",
    "slong_test = 100000\n",
    "init_test = 1000\n",
    "e_test = params.std_tfp * np.random.randn(slong_test) #New shocks\n",
    "\n",
    "# Preallocate arrays for test\n",
    "a_test            = np.zeros(slong_test)\n",
    "k_test            = np.zeros(slong_test+1)\n",
    "mu_test           = np.zeros(slong_test+1)\n",
    "production_test   = np.zeros(slong_test)\n",
    "inv_test          = np.zeros(slong_test)\n",
    "IE           = np.zeros(slong_test)\n",
    "EEE          = np.zeros(slong_test)\n",
    "cash_test         = np.zeros(slong_test)\n",
    "c_test            = np.zeros(slong_test)\n",
    "X_test            = np.zeros((slong_test, params.nb_expl_vars))\n",
    "X_next_test       = np.zeros(params.nb_expl_vars)\n",
    "linear_model_test = np.zeros(slong_test)\n",
    "y_temp1_test      = np.zeros(len(params.nodes_flat))\n",
    "\n",
    "# to store restults\n",
    "results = []\n",
    "\n",
    "np.random.seed(1)\n",
    "#for N in range(1, max_N+1):\n",
    "for (index_M, M) in enumerate(list_M):\n",
    "    slong = init + M\n",
    "    print(\"Running simulation with M =\", M)\n",
    "    # repeat several times\n",
    "    for nb_rep in range(nb_tot_reps):\n",
    "\n",
    "        b0_current = coeff_array_0.copy()  # initial guess (shape (6,))\n",
    "    \n",
    "        # innovation for state vector (not used directly in simulation here\n",
    "        # for M large, no need to redraw many times.\n",
    "        e = params.std_tfp * np.random.randn(slong)\n",
    "        # extra draws for each state: shape (slong, N)\n",
    "        E = params.std_tfp * np.random.randn(slong, N)\n",
    "    \n",
    "        # Preallocate arrays\n",
    "        a = np.zeros(slong)\n",
    "        k      = np.zeros(slong + 1)    # capital path (slong+1 because we update k[i+1])\n",
    "        mu     = np.zeros(slong + 1)    # Lagrange multiplier on investment constraint\n",
    "        y_out      = np.zeros(slong)    # simulated y\n",
    "        production = np.zeros(slong)    # production\n",
    "        inv = np.zeros(slong)           # investment\n",
    "        cash     = np.zeros(slong)      # cash in hand\n",
    "        c = np.zeros(slong)             # consumption\n",
    "        X_data      = np.zeros((slong, params.nb_expl_vars))   # regressor matrix (6 variables)\n",
    "        X_next = np.zeros(params.nb_expl_vars) # regressor, next period\n",
    "        y_temp = np.zeros(N)            # temporary array for innovations\n",
    "    \n",
    "        # Warmup (compilation) first go\n",
    "        ## Without preallocations\n",
    "        #X_data, y_out = simulate_path_N(slong, params.kss, e, E, b0_current, params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N, params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis)\n",
    "        ## With preallocations\n",
    "        simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "    \n",
    "        start_time = time.perf_counter()\n",
    "        iter_num = 1\n",
    "        crit = 1.0\n",
    "        # Run a fixed number of iterations (or use while crit > tol)\n",
    "        while iter_num < max_iter:\n",
    "            if iter_num % redraw_shocks_every == 0:\n",
    "                e[:], E[:,:] = generate_random_arrays(slong, N, params.std_tfp)\n",
    "    \n",
    "            # Call the numba-compiled simulation to get regression data.\n",
    "            #X_data, y_out = simulate_path_N(slong, params.kss, params.css, params.std_k, params.std_c, e, E, b0_current, params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N, params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis)\n",
    "            simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "    \n",
    "            # Remove burnin and last period\n",
    "            X_reg = X_data[init:-1, :]\n",
    "            y_reg = y_out[init:-1]\n",
    "            # OLS\n",
    "            bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)\n",
    "\n",
    "            if params.regression_two_steps == True:\n",
    "                #print(f\"Step 1 coef: {bt}\")\n",
    "                # Square root of weights, when using log model\n",
    "                sqrt_w = np.exp(X_reg @ bt)\n",
    "                # Pre-multiply and then regress again\n",
    "                X_wls = X_reg * sqrt_w[:, None]\n",
    "                y_wls = y_reg * sqrt_w\n",
    "                bt, _, _, _ = np.linalg.lstsq(X_wls, y_wls, rcond=None)\n",
    "\n",
    "            \n",
    "            # Parameter update\n",
    "            b_new = gam * bt + (1 - gam) * b0_current\n",
    "            crit = np.max(np.abs(b_new - b0_current))\n",
    "            b0_current = b_new.copy()\n",
    "            if (iter_num % 10 == 0):\n",
    "                print(\"Iteration:\", iter_num, \"Conv. crit.:\", crit)\n",
    "            iter_num += 1\n",
    "        end_time = time.perf_counter()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"Elapsed time for M =\", M, \":\", elapsed, \"seconds\")\n",
    "        # Compute residuals and In-sample MSE.\n",
    "        Res = y_reg - np.dot(X_reg, b0_current)\n",
    "        MSE = np.mean(Res ** 2)\n",
    "        MSE_M[index_M] = MSE\n",
    "        # Alternative measure of accuracy\n",
    "        mean_abs_ut, mean_square_ut, std_ut, dhm_stat, c_equivalent = dhm_accuracy_test(params, b0_current, e_test)\n",
    "    \n",
    "    \n",
    "        evaluate_IE_and_EEE_Gauss_path_inplace(slong_test, params.kss, \n",
    "                                         e_test, b0_current, params.beta, params.gamma, params.alpha,\n",
    "                                         params.delta, params.rho_tfp, len(params.nodes_flat),\n",
    "                                         params.nodes_flat, params.weights, params.nb_expl_vars,\n",
    "                                         params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                         a_test, k_test, mu_test, production_test, inv_test,\n",
    "                                         IE, EEE, cash_test, c_test, X_test, X_next_test, linear_model_test,\n",
    "                                         y_temp1_test)\n",
    "    \n",
    "        MSIE_M[index_M] = np.mean(IE[init_test:-1]**2)\n",
    "        A_EEE_M[index_M] = np.mean(np.abs(EEE[init_test:-1]))\n",
    "    \n",
    "        Time_M[index_M] = elapsed\n",
    "        print(\"Final iteration M:\", M, \"Iterations:\", iter_num, \"OLS MSE:\", MSE, \"MISE:\", MSIE_M[index_M], \"Average EEE:\", A_EEE_M[index_M])\n",
    "        print(\"Final b0:\", b0_current)\n",
    "    \n",
    "        # Store the results in a dictionary\n",
    "        results.append({\n",
    "            \"repetition\": nb_rep,\n",
    "            \"k\": params.nb_expl_vars,\n",
    "            \"M\": M,\n",
    "            \"N\": N,\n",
    "            \"Time\": elapsed,\n",
    "            \"MSE\": MSE,\n",
    "            \"MSIE\": MSIE_M[index_M],\n",
    "            \"A_EEE\": A_EEE_M[index_M],\n",
    "            \"Mean_abs_u\": mean_abs_ut, \n",
    "            \"mean_square_ut\": mean_square_ut, \n",
    "            \"std_ut\": std_ut, \n",
    "            \"dhm_stat\": dhm_stat, \n",
    "            \"c_equivalent\": c_equivalent\n",
    "            })\n",
    "\n",
    "# Create a Pandas DataFrame from the results\n",
    "df_results_M = pd.DataFrame(results)\n",
    "df_results_M.to_csv(output_folder + \"df_results_M.csv\")\n",
    "print(df_results_M.head())\n",
    "\n",
    "# Create average df, averaging over repetitions\n",
    "df_results_M[\"M_init\"]    = df_results_M[\"M\"] + init #add burnin\n",
    "df_results_M[\"log_N\"]    = np.log(df_results_M[\"N\"])\n",
    "df_results_M[\"log_M\"]    = np.log(df_results_M[\"M\"])\n",
    "df_results_M[\"log_MN\"]   = np.log(df_results_M[\"M\"] * df_results_M[\"N\"])\n",
    "df_results_M[\"MN_label\"] = df_results_M[\"M\"].astype(\"str\") + \"-\" + df_results_M[\"N\"].astype(\"str\")\n",
    "\n",
    "# Remove outliers (non-convergence)\n",
    "#df_results_M = df_results_M[df_results_M[\"MSIE\"] < 1.0]\n",
    "\n",
    "df_results_average_M = df_results_M.groupby(\"MN_label\").mean().reset_index()\n",
    "df_results_average_M.sort_values(\"M\", inplace=True)\n",
    "df_results_average_M.to_csv(output_folder + \"df_results_average_M.csv\")\n",
    "print(df_results_average_M.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6517c-08c3-4bfc-bd92-2f8a798a922e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "id": "fbd6517c-08c3-4bfc-bd92-2f8a798a922e",
    "outputId": "3e38216f-8c05-4bc5-8f15-28320337331a"
   },
   "outputs": [],
   "source": [
    "create_plots(df_results_average_M[\"M\"].values, df_results_average_M[\"MSE\"].values, df_results_average_M[\"Time\"].values, df_results_average_M[\"mean_square_ut\"].values, df_results_average_M[\"dhm_stat\"].values, np.abs(df_results_average_M[\"c_equivalent\"]).values, ref_index_plot=0, label=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9b079-9f24-498b-82f4-8b4200f66184",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_results_average_M[\"M\"], np.sqrt(df_results_average_M[\"MSIE\"]), label=\"data\")\n",
    "plt.plot(df_results_average_M[\"M\"], np.sqrt(df_results_average_M[\"MSIE\"]))\n",
    "plt.plot(df_results_average_M[\"M\"], np.sqrt(df_results_average_M[\"MSIE\"].values[0] * (df_results_average_M[\"M\"].values[0]/df_results_average_M[\"M\"]) ), label=\"Square root decay\")\n",
    "plt.title(\"Square root mean square integration error\")\n",
    "plt.legend()\n",
    "plt.savefig(output_folder + \"MSIE_M.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df_results_average_M[\"M\"], np.sqrt(df_results_average_M[\"A_EEE\"]), label=\"data\")\n",
    "plt.plot(df_results_average_M[\"M\"], np.sqrt(df_results_average_M[\"A_EEE\"]))\n",
    "plt.plot(df_results_average_M[\"M\"], np.sqrt(df_results_average_M[\"A_EEE\"].values[0] * (df_results_average_M[\"M\"].values[0]/df_results_average_M[\"M\"]) ), label=\"Square root decay\")\n",
    "\n",
    "plt.title(\"Average Euler equation error\")\n",
    "plt.savefig(output_folder + \"A_EEE_M.pdf\", dpi=300)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bb5ce-8a06-469e-8054-fe5707f87d1b",
   "metadata": {
    "id": "703bb5ce-8a06-469e-8054-fe5707f87d1b"
   },
   "source": [
    "### Varying M and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b2299-c2b1-4098-82ef-0b2a13f14953",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "689b2299-c2b1-4098-82ef-0b2a13f14953",
    "outputId": "8af91e7d-6153-4a52-dc93-f36aea4336bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(k[:1000])\n",
    "plt.axhline(y = params.kss, label=\"k SS\")\n",
    "plt.axhline(y = np.mean(k), label=\"k mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f48644-6e2e-44e2-9b53-2831e33c845e",
   "metadata": {
    "id": "e6f48644-6e2e-44e2-9b53-2831e33c845e"
   },
   "outputs": [],
   "source": [
    "# IF want to measure aroung target MN\n",
    "list_MN_target = [2000, 10000, 20000, 50000, 100000, 1000000] #Number for MN\n",
    "list_N_target = [1, 5, 10, 25, 50, 100, 200, 300, 500] #number of innovation draws, per state vector\n",
    "\n",
    "min_M = 100\n",
    "# Inplied values for M\n",
    "list_M = []\n",
    "list_N = []\n",
    "for MN in list_MN_target:\n",
    "    list_M += [round(int(np.maximum(random.uniform(0.8, 1.2)*(MN/N), min_M))/10)*10 for N in list_N_target] #number of state vector draws\n",
    "    list_N += list_N_target\n",
    "\n",
    "pd.DataFrame({'M': list_M, 'N': list_N}).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77976c0-cc73-4835-be8e-253c3c89a919",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c77976c0-cc73-4835-be8e-253c3c89a919",
    "outputId": "89fddc4b-a27c-4823-dbe7-4b6c504a125e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "list_N = [1, 5, 10, 25, 50, 100, 200, 300] #number of innovation draws, per state vector\n",
    "list_M = [300, 1000, 5000, 10000, 20000, 50000] #number of state vector draws\n",
    "\n",
    "init = 100 #100 #burnin, train data\n",
    "\n",
    "tol = 1e-8 # tolerance on parameter vector\n",
    "gam = 1.0  # smoothing parameter between two iterations\n",
    "max_iter = 50 # max number of iterations\n",
    "redraw_shocks_every = 1000 #redraw new realizations of innovations (new state and innovation vectors)\n",
    "\n",
    "slong_test = 100000\n",
    "init_test = 1000 #burnin, test data\n",
    "nb_tot_reps = 5 #nb of repetitions, to smooth out randomness and potential issues with measuring timing\n",
    "\n",
    "# Preallocate arrays for test\n",
    "a_test            = np.zeros(slong_test)\n",
    "k_test            = np.zeros(slong_test+1)\n",
    "mu_test           = np.zeros(slong_test+1)\n",
    "production_test   = np.zeros(slong_test)\n",
    "inv_test          = np.zeros(slong_test)\n",
    "IE           = np.zeros(slong_test)\n",
    "EEE          = np.zeros(slong_test)\n",
    "cash_test         = np.zeros(slong_test)\n",
    "c_test            = np.zeros(slong_test)\n",
    "X_test            = np.zeros((slong_test, params.nb_expl_vars))\n",
    "X_next_test       = np.zeros(params.nb_expl_vars)\n",
    "linear_model_test = np.zeros(slong_test)\n",
    "y_temp1_test      = np.zeros(len(params.nodes_flat))\n",
    "\n",
    "# to store restults\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for (index_N, N) in enumerate(list_N):\n",
    "    for (index_M, M) in enumerate(list_M):\n",
    "    #for (N, M) in zip(list_N, list_M):\n",
    "        for nb_rep in range(nb_tot_reps):\n",
    "            # Innovations for the out-sample test\n",
    "            #np.random.seed(nb_rep)\n",
    "            e_test = params.std_tfp * np.random.randn(slong_test) #New shocks\n",
    "\n",
    "            slong = init + M\n",
    "\n",
    "            b0_current = coeff_array_0.copy()  # initial guess (shape (6,))\n",
    "\n",
    "            # innovation for state vector (not used directly in simulation here\n",
    "            # for M large, no need to redraw many times.\n",
    "            e = params.std_tfp * np.random.randn(slong)\n",
    "            # extra draws for each state: shape (slong, N)\n",
    "            E = params.std_tfp * np.random.randn(slong, N)\n",
    "\n",
    "            # Preallocate arrays\n",
    "            a = np.zeros(slong)\n",
    "            k      = np.zeros(slong + 1)    # capital path (slong+1 because we update k[i+1])\n",
    "            mu     = np.zeros(slong + 1)    # Lagrange multiplier on investment constraint\n",
    "            y_out      = np.zeros(slong)    # simulated y\n",
    "            production = np.zeros(slong)    # production\n",
    "            inv = np.zeros(slong)           # investment\n",
    "            cash     = np.zeros(slong)      # cash in hand\n",
    "            c = np.zeros(slong)             # consumption\n",
    "            X_data      = np.zeros((slong, params.nb_expl_vars))   # regressor matrix (6 variables)\n",
    "            X_next = np.zeros(params.nb_expl_vars) # regressor, next period\n",
    "            y_temp = np.zeros(N)            # temporary array for innovations\n",
    "\n",
    "            # Warmup (compilation) first go\n",
    "            simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "            \n",
    "            iter_num = 1\n",
    "            crit = 1.0\n",
    "            # Run a fixed number of iterations (or use while crit > tol)\n",
    "            start_time = time.perf_counter()\n",
    "            while iter_num < max_iter:\n",
    "                if iter_num % redraw_shocks_every == 0:\n",
    "                    e[:], E[:,:] = generate_random_arrays(slong, N, params.std_tfp)\n",
    "\n",
    "                # Simulation:\n",
    "                simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "\n",
    "                # Remove burnin and last period\n",
    "                X_reg = X_data[init:-1, :]\n",
    "                y_reg = y_out[init:-1]\n",
    "                # OLS\n",
    "                bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)\n",
    "                # Parameter update\n",
    "                b_new = gam * bt + (1 - gam) * b0_current\n",
    "                crit = np.max(np.abs(b_new - b0_current))\n",
    "                b0_current = b_new.copy()\n",
    "                #print(\"Iteration:\", iter_num, \"Conv. crit.:\", crit)\n",
    "                iter_num += 1\n",
    "\n",
    "            end_time = time.perf_counter()\n",
    "            elapsed = end_time - start_time\n",
    "\n",
    "            print(f\"Iter {nb_rep}. M = {M}, N = {N}, elapsed time: {elapsed} seconds\")\n",
    "            # Compute residuals and In-sample MSE.\n",
    "            Res = y_reg - np.dot(X_reg, b0_current)\n",
    "            MSE = np.mean(Res ** 2)\n",
    "\n",
    "            # Alternative measure of accuracy\n",
    "            #mean_abs_ut, mean_square_ut, std_ut, dhm_stat, c_equivalent = dhm_accuracy_test(params, b0_current, e_test)\n",
    "\n",
    "            # Mean squared integration error and EEE\n",
    "            #IE, EEE = evaluate_IE_and_EEE_Gauss_path(slong_test, params.kss, params.css, params.std_k, params.std_c, e_test, b0_current, params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, len(params.nodes_flat), params.nodes_flat, params.weights, params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis)\n",
    "            evaluate_IE_and_EEE_Gauss_path_inplace(slong_test, params.kss, \n",
    "                                         e_test, b0_current, params.beta, params.gamma, params.alpha,\n",
    "                                         params.delta, params.rho_tfp, len(params.nodes_flat),\n",
    "                                         params.nodes_flat, params.weights, params.nb_expl_vars,\n",
    "                                         params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                         a_test, k_test, mu_test, production_test, inv_test,\n",
    "                                         IE, EEE, cash_test, c_test, X_test, X_next_test, linear_model_test,\n",
    "                                         y_temp1_test)\n",
    "\n",
    "\n",
    "            MSIE = np.mean(IE[init_test:-1]**2)\n",
    "            A_EEE = np.mean(np.abs(EEE[init_test:-1]))\n",
    "\n",
    "            print(\"Final iteration M:\", M, \"Iterations:\", iter_num, \"OLS MSE:\", MSE, \"MISE:\", MSIE, \"Average EEE:\", A_EEE)\n",
    "            print(\"Final b0:\", b0_current)\n",
    "\n",
    "            # Store the results in a dictionary\n",
    "            results.append({\n",
    "                \"repetition\": nb_rep,\n",
    "                \"k\": params.nb_expl_vars,\n",
    "                \"M\": M,\n",
    "                \"N\": N,\n",
    "                \"Time\": elapsed,\n",
    "                \"MSE\": MSE,\n",
    "                \"MSIE\": MSIE,\n",
    "                \"A_EEE\": A_EEE\n",
    "                })\n",
    "\n",
    "# Create a Pandas DataFrame from the results\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(output_folder + \"df_results.csv\")\n",
    "print(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561e8f3-7b24-41b3-895f-93bac1bcbada",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3561e8f3-7b24-41b3-895f-93bac1bcbada",
    "outputId": "8d30d816-5946-4517-a9a7-e5129c623d7c"
   },
   "outputs": [],
   "source": [
    "df_results[\"M_init\"]    = df_results[\"M\"] + init #add burnin\n",
    "df_results[\"log_N\"]    = np.log(df_results[\"N\"])\n",
    "df_results[\"log_M\"]    = np.log(df_results[\"M\"])\n",
    "df_results[\"log_MN\"]   = np.log(df_results[\"M\"] * df_results[\"N\"])\n",
    "\n",
    "df_results[\"MN_label\"] = df_results[\"M\"].astype(\"str\") + \"-\" + df_results[\"N\"].astype(\"str\")\n",
    "\n",
    "# Remove outliers (non-convergence)\n",
    "df_results = df_results[df_results[\"MSIE\"] < 1.0]\n",
    "\n",
    "df_results_average = df_results.groupby(\"MN_label\").mean().reset_index()\n",
    "print(df_results_average.head())\n",
    "\n",
    "# sigma_e**2 * k / (N**alpha * (M - k - 1))\n",
    "m = smf.ols(\"np.log(MSIE) ~ np.log(N) + np.log(M - k - 1)\", data=df_results_average).fit()\n",
    "coef_alpha = -m.params[\"np.log(N)\"]\n",
    "print(coef_alpha)\n",
    "print(m.summary())\n",
    "\n",
    "\n",
    "## Simulation + OLS time\n",
    "# 1. Time moddel\n",
    "m = smf.ols(\"Time ~ I(M*N) + M \", data=df_results_average).fit()\n",
    "print(m.summary())\n",
    "\n",
    "# 2. Extract point estimates\n",
    "c_st = m.params[\"Intercept\"]\n",
    "alpha_MN = m.params[\"I(M * N)\"]      # coeff on M*N\n",
    "alpha_M  = m.params[\"M\"]             # coeff on M\n",
    "\n",
    "# 3. Extract standard errors\n",
    "se_c_st = m.bse[\"Intercept\"]\n",
    "se_alpha_MN = m.bse[\"I(M * N)\"]      # SE of alpha_MN\n",
    "se_alpha_M  = m.bse[\"M\"]             # SE of alpha_M\n",
    "\n",
    "# 4. Extract covariance between the two slopes\n",
    "cov_M_MN = m.cov_params().loc[\"M\", \"I(M * N)\"]  # covariance between alpha_M and alpha_MN\n",
    "\n",
    "# 5. Extra full covariance matrix\n",
    "print(m.cov_params()) # full var-cov matrix\n",
    "# Reorder\n",
    "cov_mat = m.cov_params().loc[['Intercept','M','I(M * N)'], ['Intercept','M','I(M * N)']].values\n",
    "\n",
    "print(\"alpha_MN =\", alpha_MN, \"±\", se_alpha_MN)\n",
    "print(\"alpha_M  =\", alpha_M,  \"±\", se_alpha_M)\n",
    "print(\"Cov(alpha_M, alpha_MN) =\", cov_M_MN)\n",
    "\n",
    "## Simulation + OLS time\n",
    "## Checking the burnin does not change timing model\n",
    "## Should only change constant\n",
    "m = smf.ols(\"Time ~ I(M_init*N) + M_init \", data=df_results_average).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256ff0f-0d67-411e-a566-8a3021f4e36a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7256ff0f-0d67-411e-a566-8a3021f4e36a",
    "outputId": "b54261c0-b5b7-44fa-c16e-ec88fa07694f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results_average[\"log_Time\"] = np.log(df_results_average[\"Time\"])\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "# 1) Time vs N, colored by M\n",
    "axs[0, 0].scatter(df_results_average[\"N\"], df_results_average[\"Time\"], c=df_results_average[\"M\"], alpha=0.7)\n",
    "axs[0, 0].set_xlabel(\"N\")\n",
    "axs[0, 0].set_ylabel(\"Time\")\n",
    "axs[0, 0].set_title(\"Time vs N (color=M)\")\n",
    "\n",
    "# 2) Time vs M, colored by N\n",
    "axs[0, 1].scatter(df_results_average[\"M\"], df_results_average[\"Time\"], c=df_results_average[\"N\"], alpha=0.7)\n",
    "axs[0, 1].set_xlabel(\"M\")\n",
    "axs[0, 1].set_ylabel(\"Time\")\n",
    "axs[0, 1].set_title(\"Time vs M (color=N)\")\n",
    "\n",
    "# 3) log_Time vs log_N, colored by M\n",
    "axs[1, 0].scatter(df_results_average[\"log_N\"], df_results_average[\"log_Time\"], c=df_results_average[\"M\"], alpha=0.7)\n",
    "axs[1, 0].set_xlabel(\"log(N)\")\n",
    "axs[1, 0].set_ylabel(\"log(Time)\")\n",
    "axs[1, 0].set_title(\"log(Time) vs log(N) (color=M)\")\n",
    "\n",
    "# 4) log_Time vs log_M, colored by N\n",
    "axs[1, 1].scatter(df_results_average[\"log_M\"], df_results_average[\"log_Time\"], c=df_results_average[\"N\"], alpha=0.7)\n",
    "axs[1, 1].set_xlabel(\"log(M)\")\n",
    "axs[1, 1].set_ylabel(\"log(Time)\")\n",
    "axs[1, 1].set_title(\"log(Time) vs log(M) (color=N)\")\n",
    "\n",
    "# 5) log_Time vs log_MN, colored by N\n",
    "axs[2, 0].scatter(df_results_average[\"log_MN\"], df_results_average[\"log_Time\"], c=df_results_average[\"N\"], alpha=0.7)\n",
    "axs[2, 0].set_xlabel(\"log(M*N)\")\n",
    "axs[2, 0].set_ylabel(\"log(Time)\")\n",
    "axs[2, 0].set_title(\"log(Time) vs log(M*N) (color=N)\")\n",
    "\n",
    "# Remove the unused subplot\n",
    "fig.delaxes(axs[2, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_folder + \"plot_Time_MN.pdf\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b48939-d91e-4f76-b585-133bce74673e",
   "metadata": {
    "id": "e0b48939-d91e-4f76-b585-133bce74673e"
   },
   "source": [
    "#### Pareto frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e21b9-d7a2-495b-a635-dcbbbdda2e4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c04e21b9-d7a2-495b-a635-dcbbbdda2e4c",
    "outputId": "6994bbd2-d77d-4ba8-ff2a-a6b0398c6b37"
   },
   "outputs": [],
   "source": [
    "def compute_pareto_front(df, time_col='Time', mse_col='MSIE'):\n",
    "    # Sort by Time ascending\n",
    "    df_sorted = df.sort_values(by=time_col, ascending=True)\n",
    "\n",
    "    # List to store the Pareto front\n",
    "    pareto_points = []\n",
    "\n",
    "    # Keep track of the lowest MSE encountered so far\n",
    "    best_mse_so_far = float('inf')\n",
    "\n",
    "    for idx, row in df_sorted.iterrows():\n",
    "        mse_val = row[mse_col]\n",
    "        if mse_val < best_mse_so_far:\n",
    "            pareto_points.append(row)\n",
    "            best_mse_so_far = mse_val\n",
    "\n",
    "    return pd.DataFrame(pareto_points)\n",
    "\n",
    "pareto_df = compute_pareto_front(df_results_average)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df_results_average, x='Time', y='MSIE', hue='M', palette='viridis', alpha=0.7)\n",
    "#plt.plot(pareto_df['Time'], pareto_df['MSIE'], 'r-o', label='Pareto Frontier')\n",
    "\n",
    "# Now highlight the optimal points\n",
    "optimal_df = df_results_average[df_results_average['N'] == 1]\n",
    "plt.scatter(optimal_df['Time'], optimal_df['MSIE'],\n",
    "            marker='*', s=250, c='red',\n",
    "            edgecolors='black', linewidths=1,\n",
    "            label='N = 1')\n",
    "\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('MSIE')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('Time vs. MSIE, Colored by M')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_folder + \"Time_vs_MSIE_1.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "df_results_sel = df_results_average[df_results_average[\"Time\"] < 1.0]\n",
    "pareto_df = compute_pareto_front(df_results_sel)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df_results_sel, x='Time', y='MSIE', hue='M', palette='viridis', alpha=0.7)\n",
    "plt.plot(pareto_df['Time'], pareto_df['MSIE'], 'r-o', label='Pareto Frontier')\n",
    "\n",
    "# Now highlight the optimal points\n",
    "optimal_df = df_results_sel[df_results_sel['N'] == 1]\n",
    "plt.scatter(optimal_df['Time'], optimal_df['MSIE'],\n",
    "            marker='*', s=250, c='red',\n",
    "            edgecolors='black', linewidths=1,\n",
    "            label='N = 1')\n",
    "\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('MSIE')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('Time vs. MSIE, Colored by M')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_folder + \"Time_vs_MSIE_2.pdf\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481509e6-e2ac-4c96-bea1-ffc0b7dde0b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "481509e6-e2ac-4c96-bea1-ffc0b7dde0b5",
    "outputId": "d7ce45a9-4026-4609-9e52-73ef8cde9329"
   },
   "outputs": [],
   "source": [
    "pareto_df = compute_pareto_front(df_results_average, time_col='Time', mse_col='A_EEE')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df_results_average, x='Time', y='A_EEE', hue='N', palette='viridis', alpha=0.7)\n",
    "#plt.plot(pareto_df['Time'], pareto_df['A_EEE'], 'r-o', label='Pareto Frontier')\n",
    "\n",
    "# Now highlight the optimal points\n",
    "optimal_df = df_results_average[df_results_average['N'] == 1]\n",
    "plt.scatter(optimal_df['Time'], optimal_df['A_EEE'],\n",
    "            marker='*', s=250, c='red',\n",
    "            edgecolors='black', linewidths=1,\n",
    "            label='N = 1')\n",
    "\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('A_EEE')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('Time vs. EEE, Colored by N')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_folder + \"Time_vs_EEE_1.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535f407-f09e-44dc-9600-0222dda086b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2535f407-f09e-44dc-9600-0222dda086b4",
    "outputId": "73180a4c-c663-4f92-d327-fc2ead07b1d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optimal_M_N_old(T, k, alpha, alpha0, alpha1, alpha2, eps=1e-12, round_nearest = True):\n",
    "    \"\"\"\n",
    "    Compute the pair (M*, N*) that minimizes MSIE\n",
    "      E[(…)^2] ∼ σ^2 k / [N^α (M−k−1)]\n",
    "    subject to the time budget\n",
    "      T = α0 + α1⋅M⋅N + α2⋅M.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T : float\n",
    "        Total time budget (must exceed α0).\n",
    "    k : int\n",
    "        Number of regressors, including constant\n",
    "    alpha : float\n",
    "        Exponent in the integration error ( >1 for well‑posed optimum).\n",
    "    alpha0 : float\n",
    "        Intercept term (c_st).\n",
    "    alpha1 : float\n",
    "        Coefficient on M⋅N.\n",
    "    alpha2 : float\n",
    "        Coefficient on M.\n",
    "    eps : float, optional\n",
    "        Threshold below which we treat alpha2 as zero.\n",
    "    round_nearest : boolean, optional\n",
    "        If true, round to nearest 10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    M_star, N_star : tuple of floats\n",
    "        Optimal M and N.\n",
    "    \"\"\"\n",
    "    C0 = T - alpha0\n",
    "    if C0 <= 0:\n",
    "        raise ValueError(\"T must exceed alpha0\")\n",
    "    # α2 → 0 limit\n",
    "    if abs(alpha2) < eps:\n",
    "        M_star = alpha * (k + 1) / (alpha - 1)\n",
    "    else:\n",
    "        A = (alpha - 1) * C0\n",
    "        B = alpha * C0 * (k + 1)\n",
    "        # positive root of α2 M^2 + (α-1)C0 M - α C0 (k+1) = 0\n",
    "        M_star = (-A + np.sqrt(A**2 + 4 * alpha2 * B)) / (2 * alpha2)\n",
    "\n",
    "    # back out N from the time constraint\n",
    "    N_star = (C0 - alpha2 * M_star) / (alpha1 * M_star)\n",
    "\n",
    "    # round to nearest 10\n",
    "    if round_nearest == True:\n",
    "         M_star = int(np.round(M_star/10) * 10)\n",
    "         N_star = int(np.round(N_star/10) * 10)\n",
    "\n",
    "    return M_star, N_star\n",
    "\n",
    "\n",
    "def optimal_M_N(T, k, alpha, alpha0, alpha1, alpha2,\n",
    "                rho=0.0,\n",
    "                eps=1e-12,\n",
    "                round_nearest=True,\n",
    "                effective_sample_size=True):\n",
    "    \"\"\"\n",
    "    Compute the pair (M*, N*) that minimizes MSIE\n",
    "      E[(…)^2] ∼ σ^2 k / [N^α (M−k−1)]\n",
    "    subject to the time budget\n",
    "      T = α0 + α1⋅M⋅N + α2⋅M.\n",
    "\n",
    "    If effective_sample_size=True, applies AR(1) correction.\n",
    "    The effective sample size for M is:\n",
    "      M_eff = M*(1−rho)/(1+rho) <-> M = M_eff * (1+rho)/(1-rho).\n",
    "    Then, recompute N using the time budget.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T : float\n",
    "    k : int\n",
    "    alpha : float (>1)\n",
    "    alpha0 : float\n",
    "    alpha1 : float\n",
    "    alpha2 : float\n",
    "    rho : float\n",
    "      AR(1) coefficient for effective sample-size adjustment.\n",
    "    eps : float\n",
    "    round_nearest : bool\n",
    "    effective_sample_size : bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    M_star, N_star\n",
    "    \"\"\"\n",
    "    C0 = T - alpha0\n",
    "    if C0 <= 0:\n",
    "        raise ValueError(\"T must exceed alpha0\")\n",
    "\n",
    "    # 1) find the M* ignoring serial correlation\n",
    "    if abs(alpha2) < eps:\n",
    "        M_star = alpha * (k + 1) / (alpha - 1)\n",
    "    else:\n",
    "        A = (alpha - 1) * C0\n",
    "        B = alpha * C0 * (k + 1)\n",
    "        # solve α2 M^2 + (α-1)C0 M - α C0 (k+1) = 0\n",
    "        M_star = (-A + np.sqrt(A**2 + 4 * alpha2 * B)) / (2 * alpha2)\n",
    "\n",
    "    # 2) back out N* from the time constraint\n",
    "    N_star = (C0 - alpha2 * M_star) / (alpha1 * M_star)\n",
    "\n",
    "    # 3) optionally apply AR(1) effective-M correction\n",
    "    if effective_sample_size:\n",
    "        if not (-1 < rho < 1):\n",
    "            raise ValueError(\"rho must lie in (-1,1) for effective-M\")\n",
    "        # Increase the value of M* by a factor of (1 + rho) / (1 - rho).\n",
    "        # Because of serial correaltion, each observation of the state is less \"valuable\"\n",
    "        M_eff = M_star * (1 + rho) / (1 - rho)\n",
    "        # recompute N under same time budget\n",
    "        N_eff = (C0 - alpha2 * M_eff) / (alpha1 * M_eff)\n",
    "        M_star, N_star = M_eff, N_eff\n",
    "\n",
    "    # 4) optionally round\n",
    "    if round_nearest:\n",
    "        M_star = int(np.round(M_star / 10) * 10)\n",
    "        N_star = int(np.round(N_star / 10) * 10)\n",
    "\n",
    "    return M_star, N_star\n",
    "\n",
    "# Delta method to calculate uncertainty aroud M *and N*\n",
    "def se_MN_star_full(\n",
    "    M_star, N_star, T, k, alpha,\n",
    "    alpha_0, alpha_M, alpha_MN,\n",
    "    se_alpha_0, se_alpha_M, se_alpha_MN,\n",
    "    cov_mat          # 3×3 numpy array from m.cov_params().values\n",
    "):\n",
    "    # Precompute\n",
    "    C0 = T - alpha_0\n",
    "    b  = (alpha - 1)*C0\n",
    "    D  = np.sqrt(b*b + 4*alpha_M*alpha*C0*(k+1))\n",
    "\n",
    "    # 1) partials for M*\n",
    "    dM_d0 = -1/(2*alpha_M)*((alpha-1)\n",
    "             - ((alpha-1)**2 *C0 + 2*alpha*alpha_M*(k+1))/D)\n",
    "    dM_dM = (alpha*C0*(k+1)/D - M_star)/alpha_M\n",
    "    dM_dMN= 0.0\n",
    "\n",
    "    grad_M = np.array([dM_d0, dM_dM, dM_dMN])\n",
    "    var_M  = grad_M @ cov_mat @ grad_M\n",
    "    se_M   = np.sqrt(var_M)\n",
    "\n",
    "    # 2) partials for N*\n",
    "    dN_d0 = (1/(alpha_MN*M_star)\n",
    "             - (C0 - alpha_M*M_star)/(alpha_MN*(M_star**2))*dM_d0)\n",
    "    dN_dM = (-1/alpha_MN\n",
    "             - (C0 - alpha_M*M_star)/(alpha_MN*(M_star**2))*dM_dM)\n",
    "    dN_dMN= -N_star/alpha_MN\n",
    "\n",
    "    grad_N = np.array([dN_d0, dN_dM, dN_dMN])\n",
    "    var_N  = grad_N @ cov_mat @ grad_N\n",
    "    se_N   = np.sqrt(var_N)\n",
    "\n",
    "    return se_M, se_N\n",
    "\n",
    "target_time = 1\n",
    "for eff_M in [True, False]:\n",
    "    for alpha_selected in [coef_alpha, 1.0]:\n",
    "        M_opt, N_opt = optimal_M_N(target_time, params.nb_expl_vars, alpha_selected, c_st, alpha_MN, alpha_M, rho = params.rho_tfp, effective_sample_size = eff_M)\n",
    "    \n",
    "        se_M_opt, se_N_opt = se_MN_star_full(M_opt, N_opt, target_time, params.nb_expl_vars, alpha_selected,\n",
    "                                            c_st, alpha_M, alpha_MN,\n",
    "                                            se_c_st, se_alpha_M, se_alpha_MN, cov_mat)\n",
    "        print(f\"alpha: {alpha_selected}. Effective sample size M: {eff_M}\")\n",
    "        print(f\"M*: {M_opt} +/- 2 * {se_M_opt}\")\n",
    "        print(f\"N*: {N_opt} +/- 2 * {se_N_opt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51787f4-1d07-4e3c-9e19-a28d079e480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + params.rho_tfp) / (1 - params.rho_tfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03ede9-738a-48e5-bd27-d2fc71b6db55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6e03ede9-738a-48e5-bd27-d2fc71b6db55",
    "outputId": "8dc43701-b01d-4abf-af17-7675c3aeb603"
   },
   "outputs": [],
   "source": [
    "# 1) Pivot MSIE into a matrix with rows=M and columns=N\n",
    "df_sel = df_results_average[df_results_average[\"MSIE\"] < 1.0].copy()\n",
    "\n",
    "df_sel[\"log_MSIE\"] = np.log10(df_sel[\"MSIE\"])\n",
    "df_sel[\"log_MSIE_Time\"] = np.log10(df_sel[\"MSIE\"]/df_sel[\"Time\"])\n",
    "df_sel[\"log_MSIE_x_Time\"] = np.log10(df_sel[\"MSIE\"]*df_sel[\"Time\"]/10)\n",
    "\n",
    "\n",
    "# TIME\n",
    "pivot = df_sel.pivot_table(\n",
    "    index='M',\n",
    "    columns='N',\n",
    "    values='Time',\n",
    "    aggfunc='mean'        # ensures proper aggregation if duplicates exist\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "# 2) Create a mask of the NaN cells\n",
    "mask = pivot.isnull()\n",
    "\n",
    "# 3) Plot with seaborn, masking NaNs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    pivot,\n",
    "    mask=mask,           # hide cells where pivot is NaN\n",
    "    cmap='viridis',\n",
    "    cbar_kws={'label': 'Time'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='white'\n",
    ")\n",
    "\n",
    "plt.xlabel('N (innovation draws)')\n",
    "plt.ylabel('M (state draws)')\n",
    "plt.title('Heatmap of Time over (M, N)')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "pivot = df_sel.pivot_table(\n",
    "    index='M',\n",
    "    columns='N',\n",
    "    values='log_MSIE',\n",
    "    aggfunc='mean'        # ensures proper aggregation if duplicates exist\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "# 2) Create a mask of the NaN cells\n",
    "mask = pivot.isnull()\n",
    "\n",
    "# 3) Plot with seaborn, masking NaNs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    pivot,\n",
    "    mask=mask,           # hide cells where pivot is NaN\n",
    "    cmap='viridis',\n",
    "    cbar_kws={'label': 'log_MSIE'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='white'\n",
    ")\n",
    "\n",
    "plt.xlabel('N (innovation draws)')\n",
    "plt.ylabel('M (state draws)')\n",
    "plt.title('Heatmap of MSIE over (M, N)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Accuracy-Time\n",
    "pivot = df_sel.pivot_table(\n",
    "    index='M',\n",
    "    columns='N',\n",
    "    values='log_MSIE_x_Time',\n",
    "    aggfunc='mean'        # ensures proper aggregation if duplicates exist\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "# 2) Create a mask of the NaN cells\n",
    "mask = pivot.isnull()\n",
    "\n",
    "# 3) Plot with seaborn, masking NaNs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    pivot,\n",
    "    mask=mask,           # hide cells where pivot is NaN\n",
    "    cmap='viridis',\n",
    "    cbar_kws={'label': 'log_MSIE_x_Time'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='white'\n",
    ")\n",
    "\n",
    "plt.xlabel('N (innovation draws)')\n",
    "plt.ylabel('M (state draws)')\n",
    "plt.title('Heatmap of (MSIExTime)/10 over (M, N)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79738258-064d-4789-8e15-6e8c41f7f013",
   "metadata": {
    "id": "79738258-064d-4789-8e15-6e8c41f7f013"
   },
   "source": [
    "### Variation around a target time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3cde7f-5080-4fc9-b0df-af7ae22a6445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Redo regression, but with data close to target times\n",
    "df_selected = df_results_average[df_results_average[\"Time\"] < 10]\n",
    "\n",
    "# Accuracy model\n",
    "m = smf.ols(\"np.log(MSIE) ~ np.log(N) + np.log(M - k - 1)\", data=df_selected).fit()\n",
    "#coef_alpha = -m.params[\"np.log(N)\"] #Use estimated value\n",
    "coef_alpha = 1.0 #Use theoretical value\n",
    "print(coef_alpha)\n",
    "print(m.summary())\n",
    "\n",
    "## Simulation + OLS time\n",
    "# 1. Time moddel\n",
    "m = smf.ols(\"Time ~ I(M*N) + M \", data=df_results_average).fit()\n",
    "print(m.summary())\n",
    "\n",
    "# 2. Extract point estimates\n",
    "c_st = m.params[\"Intercept\"]\n",
    "alpha_MN = m.params[\"I(M * N)\"]      # coeff on M*N\n",
    "alpha_M  = m.params[\"M\"]             # coeff on M\n",
    "\n",
    "# 3. Extract standard errors\n",
    "se_c_st = m.bse[\"Intercept\"]\n",
    "se_alpha_MN = m.bse[\"I(M * N)\"]      # SE of alpha_MN\n",
    "se_alpha_M  = m.bse[\"M\"]             # SE of alpha_M\n",
    "\n",
    "# 4. Extract covariance between the two slopes\n",
    "cov_M_MN = m.cov_params().loc[\"M\", \"I(M * N)\"]  # covariance between alpha_M and alpha_MN\n",
    "\n",
    "# 5. Extra full covariance matrix\n",
    "print(m.cov_params()) # full var-cov matrix\n",
    "# Reorder\n",
    "cov_mat = m.cov_params().loc[['Intercept','M','I(M * N)'], ['Intercept','M','I(M * N)']].values\n",
    "\n",
    "print(\"alpha_MN =\", alpha_MN, \"±\", se_alpha_MN)\n",
    "print(\"alpha_M  =\", alpha_M,  \"±\", se_alpha_M)\n",
    "print(\"Cov(alpha_M, alpha_MN) =\", cov_M_MN)\n",
    "\n",
    "\n",
    "list_N        = []\n",
    "list_M        = []\n",
    "list_optimal  = []\n",
    "list_Time     = []\n",
    "list_se_N = []\n",
    "list_se_M = []\n",
    "\n",
    "list_target_times = [0.1, 0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "min_M = 50 #Otherwise blows up\n",
    "\n",
    "for target_time in list_target_times:\n",
    "    # 1) build candidate grid\n",
    "    list_N_temp = [1, 10, 100, 1000, 10000]\n",
    "    N_array     = np.array(list_N_temp)\n",
    "\n",
    "    # recover M from your linear timing law (without burn-in)\n",
    "    vals = (target_time - c_st) / (alpha_M + alpha_MN * N_array)\n",
    "\n",
    "    # 2) correct rounding: apply *10 before comprehension\n",
    "    M_vals = np.round(vals/10) * 10\n",
    "    list_M_temp = [int(max(m, min_M)) for m in M_vals]  # ensure M ≥ min_M\n",
    "\n",
    "    # 3) append the non‐optimal candidates\n",
    "    list_N       += list_N_temp\n",
    "    list_M       += list_M_temp\n",
    "    list_optimal += [0] * len(list_N_temp)\n",
    "    list_Time    += [target_time] * len(list_N_temp)  # align one‐to‐one\n",
    "    list_se_N += [0] * len(list_N_temp)\n",
    "    list_se_M += [0] * len(list_M_temp)\n",
    "    \n",
    "    # 4) compute the theoretical optimum with burn-in\n",
    "    M_opt, N_opt = optimal_M_N(target_time, params.nb_expl_vars, coef_alpha, c_st, alpha_MN, alpha_M, rho = params.rho_tfp, effective_sample_size = params.effective_sample_size)\n",
    "    se_M_opt, se_N_opt = se_MN_star_full(M_opt, N_opt, target_time, params.nb_expl_vars, coef_alpha,\n",
    "                                        c_st, alpha_M, alpha_MN,\n",
    "                                        se_c_st, se_alpha_M, se_alpha_MN, cov_mat)\n",
    "\n",
    "    print(f\"alpha: {coef_alpha}\")\n",
    "    print(f\"M*: {M_opt} +/- 2 * {se_M_opt}\")\n",
    "    print(f\"N*: {N_opt} +/- 2 * {se_N_opt}\")\n",
    "\n",
    "    # 5) append the optimal point\n",
    "    list_N.append(int(np.maximum(1, N_opt)))\n",
    "    list_M.append(int(M_opt))\n",
    "    list_optimal.append(1)\n",
    "    list_Time.append(target_time)\n",
    "    list_se_N.append(se_N_opt)\n",
    "    list_se_M.append(se_M_opt)\n",
    "\n",
    "# 6) build DataFrame\n",
    "df_MN = pd.DataFrame({\n",
    "    \"M\":           list_M,\n",
    "    \"N\":           list_N,\n",
    "    \"is_optimal\":  list_optimal,\n",
    "    \"target_time\": list_Time,\n",
    "    \"se_M\":        list_se_M,\n",
    "    \"se_N\":        list_se_N\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933fd499-8197-4769-bb40-23b1114ebace",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "933fd499-8197-4769-bb40-23b1114ebace",
    "outputId": "ad2c3bce-6cef-476b-bd0e-ef16b5ebe9ed"
   },
   "outputs": [],
   "source": [
    "#----------------------------------\n",
    "tol = 1e-8 # tolerance on parameter vector\n",
    "gam = 1.0  # smoothing parameter between two iterations\n",
    "max_iter = 50 # max number of iterations\n",
    "redraw_shocks_every = 1000 #redraw new realizations of innovations (new state and innovation vectors)\n",
    "\n",
    "slong_test = 100000\n",
    "init_test = 100\n",
    "nb_tot_reps = 10 #nb of repetitions, to smooth out randomness and potential issues with measuring timing\n",
    "\n",
    "# Preallocate arrays for test\n",
    "a_test            = np.zeros(slong_test)\n",
    "k_test            = np.zeros(slong_test+1)\n",
    "mu_test           = np.zeros(slong_test+1)\n",
    "production_test   = np.zeros(slong_test)\n",
    "inv_test          = np.zeros(slong_test)\n",
    "IE           = np.zeros(slong_test)\n",
    "EEE          = np.zeros(slong_test)\n",
    "cash_test         = np.zeros(slong_test)\n",
    "c_test            = np.zeros(slong_test)\n",
    "X_test            = np.zeros((slong_test, params.nb_expl_vars))\n",
    "X_next_test       = np.zeros(params.nb_expl_vars)\n",
    "linear_model_test = np.zeros(slong_test)\n",
    "y_temp1_test      = np.zeros(len(params.nodes_flat))\n",
    "\n",
    "# to store restults\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for (N, M, is_optimal) in zip(list_N, list_M, list_optimal):\n",
    "    for nb_rep in range(nb_tot_reps):\n",
    "        #np.random.seed(nb_rep)\n",
    "        # Innovations for the out-sample test\n",
    "        e_test = params.std_tfp * np.random.randn(slong_test) #New shocks\n",
    "\n",
    "        slong = init + M\n",
    "\n",
    "        b0_current = coeff_array_0.copy()  # initial guess (shape (6,))\n",
    "\n",
    "        # innovation for state vector (not used directly in simulation here\n",
    "        # for M large, no need to redraw many times.\n",
    "        e = params.std_tfp * np.random.randn(slong)\n",
    "        # extra draws for each state: shape (slong, N)\n",
    "        E = params.std_tfp * np.random.randn(slong, N)\n",
    "\n",
    "        # Preallocate arrays\n",
    "        a = np.zeros(slong)\n",
    "        k      = np.zeros(slong + 1)    # capital path (slong+1 because we update k[i+1])\n",
    "        mu     = np.zeros(slong + 1)    # Lagrange multiplier on investment constraint\n",
    "        y_out      = np.zeros(slong)    # simulated y\n",
    "        production = np.zeros(slong)    # production\n",
    "        inv = np.zeros(slong)           # investment\n",
    "        cash     = np.zeros(slong)      # cash in hand\n",
    "        c = np.zeros(slong)             # consumption\n",
    "        X_data      = np.zeros((slong, params.nb_expl_vars))   # regressor matrix (6 variables)\n",
    "        X_next = np.zeros(params.nb_expl_vars) # regressor, next period\n",
    "        y_temp = np.zeros(N)            # temporary array for innovations\n",
    "\n",
    "        # Warmup (compilation) first go\n",
    "        simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "\n",
    "        iter_num = 1\n",
    "        crit = 1.0\n",
    "        # Run a fixed number of iterations (or use while crit > tol)\n",
    "        start_time = time.perf_counter()\n",
    "        while iter_num < max_iter:\n",
    "            if iter_num % redraw_shocks_every == 0:\n",
    "                e[:], E[:,:] = generate_random_arrays(slong, N, params.std_tfp)\n",
    "\n",
    "            # Simulation:\n",
    "            simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,\n",
    "                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,\n",
    "                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)\n",
    "\n",
    "            # Remove burnin and last period\n",
    "            X_reg = X_data[init:-1, :]\n",
    "            y_reg = y_out[init:-1]\n",
    "            # OLS\n",
    "            bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)\n",
    "            # Parameter update\n",
    "            b_new = gam * bt + (1 - gam) * b0_current\n",
    "            crit = np.max(np.abs(b_new - b0_current))\n",
    "            b0_current = b_new.copy()\n",
    "            #print(\"Iteration:\", iter_num, \"Conv. crit.:\", crit)\n",
    "            iter_num += 1\n",
    "        end_time = time.perf_counter()\n",
    "        elapsed = end_time - start_time\n",
    "\n",
    "        print(f\"Iter {nb_rep}. M = {M}, N = {N}, elapsed time: {elapsed} seconds\")\n",
    "        # Compute residuals and In-sample MSE.\n",
    "        Res = y_reg - np.dot(X_reg, b0_current)\n",
    "        MSE = np.mean(Res ** 2)\n",
    "\n",
    "        # Alternative measure of accuracy\n",
    "        #mean_abs_ut, mean_square_ut, std_ut, dhm_stat, c_equivalent = dhm_accuracy_test(params, b0_current, e_test)\n",
    "        # Mean squared integration error and EEE\n",
    "        evaluate_IE_and_EEE_Gauss_path_inplace(slong_test, params.kss, \n",
    "                                         e_test, b0_current, params.beta, params.gamma, params.alpha,\n",
    "                                         params.delta, params.rho_tfp, len(params.nodes_flat),\n",
    "                                         params.nodes_flat, params.weights, params.nb_expl_vars,\n",
    "                                         params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,\n",
    "                                         a_test, k_test, mu_test, production_test, inv_test,\n",
    "                                         IE, EEE, cash_test, c_test, X_test, X_next_test, linear_model_test,\n",
    "                                         y_temp1_test)\n",
    "\n",
    "\n",
    "        MSIE = np.mean(IE[init_test:-1]**2)\n",
    "        A_EEE = np.mean(np.abs(EEE[init_test:-1]))\n",
    "\n",
    "        print(\"Final iteration M:\", M, \"Iterations:\", iter_num, \"OLS MSE:\", MSE, \"MISE:\", MSIE, \"Average EEE:\", A_EEE)\n",
    "        print(\"Final b0:\", b0_current)\n",
    "\n",
    "        # Store the results in a dictionary\n",
    "        results.append({\n",
    "            \"repetition\": nb_rep,\n",
    "            \"k\": params.nb_expl_vars,\n",
    "            \"M\": M,\n",
    "            \"N\": N,\n",
    "            \"Time\": elapsed,\n",
    "            \"MSE\": MSE,\n",
    "            \"MSIE\": MSIE,\n",
    "            \"A_EEE\": A_EEE,\n",
    "            \"is_optimal\": is_optimal\n",
    "        })\n",
    "\n",
    "# Create a Pandas DataFrame from the results\n",
    "df_results_2 = pd.DataFrame(results)\n",
    "df_results_2.to_csv(output_folder + \"df_results_2.csv\")\n",
    "print(df_results_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25bc31-b4e1-4067-9810-80fb993faa05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "id": "0f25bc31-b4e1-4067-9810-80fb993faa05",
    "outputId": "5fd97f34-c1aa-42e7-971d-4c4e1694669e"
   },
   "outputs": [],
   "source": [
    "df_results_2[\"log_N\"]    = np.log(df_results_2[\"N\"])\n",
    "df_results_2[\"log_M\"]    = np.log(df_results_2[\"M\"])\n",
    "df_results_2[\"log_MN\"]   = np.log(df_results_2[\"M\"] * df_results_2[\"N\"])\n",
    "\n",
    "df_results_2[\"MN_label\"] = df_results_2[\"M\"].astype(\"str\") + \"-\" + df_results_2[\"N\"].astype(\"str\")\n",
    "df_results_average_2 = df_results_2.groupby(\"MN_label\").mean().reset_index()\n",
    "print(df_results_average_2.head())\n",
    "\n",
    "\n",
    "pareto_df = compute_pareto_front(df_results_average_2)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df_results_average_2, x='Time', y='MSIE', alpha=0.7)\n",
    "plt.plot(pareto_df['Time'], pareto_df['MSIE'], 'r-o', label='Pareto Frontier')\n",
    "\n",
    "# Now highlight the optimal points\n",
    "#optimal_df_0 = df_results_average_2[df_results_average_2['N'] == 1]\n",
    "optimal_df = df_results_average_2[df_results_average_2['is_optimal'] == 1]\n",
    "\n",
    "plt.scatter(optimal_df['Time'], optimal_df['MSIE'],\n",
    "            marker='*', s=250, c='red',\n",
    "            edgecolors='black', linewidths=1,\n",
    "            label='Optimal (M, N)')\n",
    "\n",
    "\n",
    "df_one = df_results_average_2[df_results_average_2['N'] == 1]\n",
    "plt.scatter(df_one['Time'], df_one['MSIE'],\n",
    "            marker='+', s=250, c='red',\n",
    "            edgecolors='black', linewidths=1,\n",
    "            label='N = 1')\n",
    "\n",
    "\n",
    "for T in list_target_times:\n",
    "    plt.axvline(x = T, color = 'b')\n",
    "\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('MSIE')\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.title('Time vs. MSIE, Colored by N')\n",
    "plt.legend(loc= \"upper right\")\n",
    "plt.grid(True)\n",
    "plt.savefig(output_folder + \"Time_vs_MSIE_3.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78002f6f-5736-4f65-8457-2874c5de8222",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "78002f6f-5736-4f65-8457-2874c5de8222",
    "outputId": "ed262c95-e329-4f09-8e7e-2f2598280d22"
   },
   "outputs": [],
   "source": [
    "for (plot_index, threshold_value) in enumerate([1, 1e6]):\n",
    "  for log_yscale in [True, False]:\n",
    "      # Select df for non-optimal\n",
    "      df = df_results_average_2.copy()\n",
    "      df = df[df[\"is_optimal\"] == 0]\n",
    "      df['N_cat'] = df['N'].astype(int).astype(str).astype('category')\n",
    "    \n",
    "      # Now plot:\n",
    "      plt.figure(figsize=(8,6))\n",
    "      sns.scatterplot(\n",
    "          data=df[df[\"MSIE\"] < threshold_value],\n",
    "          x='Time',\n",
    "          y='MSIE',\n",
    "          style='N_cat',\n",
    "          legend='full',\n",
    "          hue=\"N_cat\",\n",
    "          alpha=0.7,\n",
    "          s=100\n",
    "      )\n",
    "    \n",
    "      plt.scatter(optimal_df['Time'], optimal_df['MSIE'],\n",
    "                  marker='*', s=250, c='red',\n",
    "                  edgecolors='black', linewidths=1,\n",
    "                  label='N*')\n",
    "    \n",
    "      plt.legend(title='N', loc='best')\n",
    "      plt.xlabel('Time (s)')\n",
    "      plt.ylabel('MSIE')\n",
    "      \n",
    "      if log_yscale == True:\n",
    "          plt.yscale('log')\n",
    "          #plt.title('Time vs MSIE by N')\n",
    "          plt.savefig(output_folder + f\"Time_vs_MSIE_{4 + plot_index}.pdf\", dpi=300)\n",
    "          \n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b1dce-5de4-47a1-b47d-b335f09baa08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "6f0b1dce-5de4-47a1-b47d-b335f09baa08",
    "outputId": "6a05f461-ab5d-46b0-b103-b3a34291182e"
   },
   "outputs": [],
   "source": [
    "optimal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ffcb3-377d-4c48-861a-5ac03e1594aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "513ffcb3-377d-4c48-861a-5ac03e1594aa",
    "outputId": "8e87eeed-4c6e-408f-97b0-9066a1fcef6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results_average_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57cb92-746b-4603-a4a0-79ac7dd8cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da58e40-1602-4156-b038-97c707018cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MN_sel = df_MN[df_MN[\"is_optimal\"] == 1]\n",
    "df = df_results_average_2[df_results_average_2[\"is_optimal\"] == True].copy()\n",
    "df.sort_values(\"Time\", inplace=True)\n",
    "plt.scatter(df[\"Time\"], df[\"N\"], label=\"N* (theory)\")\n",
    "plt.fill_between(df[\"Time\"], df_MN_sel['N'] -1.96*df_MN_sel['se_N'], df_MN_sel['N']+ 1.96*df_MN_sel['se_N'], alpha=0.5)\n",
    "\n",
    "plt.scatter(pareto_df[\"Time\"], pareto_df[\"N\"], label=\"N* (actual)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df = df_results_average_2[df_results_average_2[\"is_optimal\"] == True].copy()\n",
    "df.sort_values(\"Time\", inplace=True)\n",
    "plt.scatter(df[\"Time\"], df[\"M\"], label=\"M* (theory)\")\n",
    "plt.fill_between(df[\"Time\"], df_MN_sel['M'] -1.96*df_MN_sel['se_M'], df_MN_sel['M']+ 1.96*df_MN_sel['se_M'], alpha=0.5)\n",
    "plt.scatter(pareto_df[\"Time\"], pareto_df[\"M\"], label=\"M* (actual)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121af5f",
   "metadata": {
    "id": "3121af5f"
   },
   "source": [
    "---\n",
    "\n",
    "## Hardware details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741df185",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "741df185",
    "outputId": "c8c0c162-b656-4205-e6c6-57b1bdc930be"
   },
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dbee4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58dbee4e",
    "outputId": "f41aa7a4-1e32-4a1c-e657-18cc44b17748"
   },
   "outputs": [],
   "source": [
    "cpuinfo.get_cpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24459a5-9ad4-4484-8248-2a66b46bab8a",
   "metadata": {
    "id": "d24459a5-9ad4-4484-8248-2a66b46bab8a"
   },
   "source": [
    "### Saving and closing on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956e88f-91d0-4a29-83f7-f53f1d5cd95d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0956e88f-91d0-4a29-83f7-f53f1d5cd95d",
    "outputId": "f4164dee-0607-4db9-efac-9a5416e426b2"
   },
   "outputs": [],
   "source": [
    "# Copy to drive\n",
    "if on_Colab==True:\n",
    "    drive.mount('/gdrive', force_remount=True)\n",
    "\n",
    "    zip_filename = f\"{output_extension}\"  # No '.zip' extension here yet (shutil adds it)\n",
    "    output_zip_full_path = g_drive_path + zip_filename\n",
    "\n",
    "    # Compress the folder into the named zip file\n",
    "    shutil.make_archive(output_zip_full_path, 'zip', output_extension)\n",
    "\n",
    "    # Unmount Drive safely\n",
    "    drive.flush_and_unmount()\n",
    "    print(f'Backup {zip_filename}.zip completed and saved to Google Drive at {g_drive_path}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cb57c-ceb8-4d05-86d7-f334a927ed61",
   "metadata": {
    "id": "d31cb57c-ceb8-4d05-86d7-f334a927ed61"
   },
   "outputs": [],
   "source": [
    "disconnect_when_done = False\n",
    "\n",
    "if on_Colab==True:\n",
    "    # Wait 2 minutes\n",
    "    time.sleep(120)\n",
    "\n",
    "    ## Close session\n",
    "    from google.colab import runtime\n",
    "    if disconnect_when_done==True:\n",
    "      print(\"Closing runtime\")\n",
    "      runtime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b8607",
   "metadata": {
    "id": "0b9b8607"
   },
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    "*  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
